{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTZAN Dataset Expressions Analysis\n",
    "\n",
    "This notebook analyzes the expressions from top 250 unique features for GTZAN dataset.\n",
    "\n",
    "**Analysis Tasks:**\n",
    "1. Extract base features from complex expressions\n",
    "2. Create co-occurrence matrices showing how often base features appear together\n",
    "3. Create performance matrices showing average test_auc for co-occurring features\n",
    "4. Generate heatmap visualizations for both E23 and ALL62 feature sets\n",
    "\n",
    "**Input Files:**\n",
    "- GTZAN_ALL62_top250_unique_20250905_175526.pkl\n",
    "- GTZAN_E23_top250_unique_20250905_175526.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _canonical_pair(a, b):\n",
    "    \"\"\"Unordered, deterministic pair for symmetric matrices.\"\"\"\n",
    "    return tuple(sorted((a, b), key=lambda x: str(x)))\n",
    "\n",
    "def _rank_all_cells(df: pd.DataFrame, *, symmetric: bool, include_diagonal: bool, dropna: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute GLOBAL dense ranks (1 = highest) for ALL cells of a DataFrame.\n",
    "    If symmetric, collapse (i,j) and (j,i) using canonical pairs and keep the MAX value.\n",
    "    Returns columns: row, col, value, rank\n",
    "    \"\"\"\n",
    "    s = df.stack(dropna=dropna)  # (row,col)->value\n",
    "    if s.empty:\n",
    "        return pd.DataFrame(columns=[\"row\", \"col\", \"value\", \"rank\"])\n",
    "\n",
    "    if not symmetric:\n",
    "        out = s.reset_index()\n",
    "        out.columns = [\"row\", \"col\", \"value\"]\n",
    "    else:\n",
    "        tmp = s.reset_index()\n",
    "        tmp.columns = [\"row\", \"col\", \"value\"]\n",
    "        if not include_diagonal:\n",
    "            tmp = tmp[tmp[\"row\"] != tmp[\"col\"]]\n",
    "        tmp[\"canon\"] = tmp.apply(lambda r: _canonical_pair(r[\"row\"], r[\"col\"]), axis=1)\n",
    "        g = (tmp.groupby(\"canon\", as_index=False)\n",
    "                 .agg(value=(\"value\", \"max\")))\n",
    "        g[\"row\"] = g[\"canon\"].apply(lambda t: t[0])\n",
    "        g[\"col\"] = g[\"canon\"].apply(lambda t: t[1])\n",
    "        out = g[[\"row\", \"col\", \"value\"]]\n",
    "\n",
    "    out[\"rank\"] = out[\"value\"].rank(method=\"dense\", ascending=False).astype(int)\n",
    "    return out.sort_values([\"rank\", \"value\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "def top_m_by_df2_with_df1_rank(df1: pd.DataFrame, df2: pd.DataFrame, *,\n",
    "                               m: int = 20,\n",
    "                               symmetric: bool = False,\n",
    "                               include_diagonal: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    DF2-centric view:\n",
    "      - Take the GLOBAL top-m cells of df2 (dense rank 1..m; includes all ties at m).\n",
    "      - For each, show df1's GLOBAL rank and value at the same coordinate.\n",
    "    Works for symmetric (unordered coords) and non-symmetric (ordered) matrices.\n",
    "    Returns columns: rank_df2, row, col, value_df2, rank_df1, value_df1\n",
    "    \"\"\"\n",
    "    df1_all = _rank_all_cells(df1, symmetric=symmetric, include_diagonal=include_diagonal)\n",
    "    df2_all = _rank_all_cells(df2, symmetric=symmetric, include_diagonal=include_diagonal)\n",
    "\n",
    "    df1_all = df1_all.rename(columns={\"value\": \"value_df1\", \"rank\": \"rank_df1\"})\n",
    "    df2_all = df2_all.rename(columns={\"value\": \"value_df2\", \"rank\": \"rank_df2\"})\n",
    "\n",
    "    # Select df2's global top-m (dense ranks include ties automatically)\n",
    "    df2_top_m = df2_all[df2_all[\"rank_df2\"] <= m].copy()\n",
    "\n",
    "    # Join df1's global rank/value at same coordinates\n",
    "    out = df2_top_m.merge(df1_all, on=[\"row\", \"col\"], how=\"left\")\n",
    "\n",
    "    # Optional: add percentiles for easier reading\n",
    "    total_df1 = len(df1_all)\n",
    "    total_df2 = len(df2_all)\n",
    "    out[\"df1_percentile\"] = out[\"rank_df1\"] / total_df1  # 0 ~ best, 1 ~ worst\n",
    "    out[\"df2_percentile\"] = out[\"rank_df2\"] / total_df2\n",
    "\n",
    "    # Order by df2 priority, then df1\n",
    "    out = out[[\"rank_df2\", \"row\", \"col\", \"value_df2\", \"rank_df1\", \"value_df1\", \"df1_percentile\", \"df2_percentile\"]] \\\n",
    "           .sort_values([\"rank_df2\", \"rank_df1\"], ascending=[True, True], na_position=\"last\") \\\n",
    "           .reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# Choose m\n",
    "M = 200\n",
    "INCLUDE_DIAGONAL = True\n",
    "\n",
    "# Pair 1 (not symmetric)\n",
    "tbl_p1 = top_m_by_df2_with_df1_rank(\n",
    "    e23_op_feat_cooccur, e23_op_feat_performance,\n",
    "    m=M, symmetric=False, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Pair 2 (not symmetric)\n",
    "tbl_p2 = top_m_by_df2_with_df1_rank(\n",
    "    all62_op_feat_cooccur, all62_op_feat_performance,\n",
    "    m=M, symmetric=False, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Pair 3 (self-matrix, symmetric)\n",
    "tbl_p3 = top_m_by_df2_with_df1_rank(\n",
    "    e23_cooccur, e23_performance,\n",
    "    m=M, symmetric=True, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Pair 4 (self-matrix, symmetric)\n",
    "tbl_p4 = top_m_by_df2_with_df1_rank(\n",
    "    all62_cooccur, all62_performance,\n",
    "    m=M, symmetric=True, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Example: view first rows\n",
    "display(tbl_p2.head(55))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Set matplotlib parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 11,\n",
    "    'figure.titlesize': 16\n",
    "})\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Base Feature Sets and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base paths\n",
    "BASE_PATH = Path('E:/Oxford/Extra/ICASSP/Draft_1/GTZAN-data')\n",
    "FEATURES_PATH = BASE_PATH / 'Ref_Perceptual_features'\n",
    "OUTPUT_PATH = BASE_PATH\n",
    "\n",
    "# Input files\n",
    "INPUT_FILES = {\n",
    "    'ALL62': FEATURES_PATH / 'GTZAN_ALL62_top500_unique_20250905_202835.pkl',\n",
    "    'E23': FEATURES_PATH / 'GTZAN_E23_top500_unique_20250905_202835.pkl'\n",
    "}\n",
    "\n",
    "# Base feature definitions\n",
    "E23 = [\n",
    "    'Danceability', 'Loudness', 'Chords-Changes-Rate', 'Dynamic-Complexity',\n",
    "    'Zerocrossingrate', 'Chords-Number-Rate', 'Pitch-Salience',\n",
    "    'Spectral-Centroid', 'Spectral-Complexity', 'Spectral-Decrease',\n",
    "    'Spectral-Energyband-High', 'Spectral-Energyband-Low',\n",
    "    'Spectral-Energyband-Middle-High', 'Spectral-Energyband-Middle-Low',\n",
    "    'Spectral-Entropy', 'Spectral-Flux', 'Spectral-Rolloff',\n",
    "    'Spectral-Spread', 'Onset-Rate', 'Length', 'BPM', 'Beats-Loud',\n",
    "    'Vocal-Instrumental'\n",
    "]\n",
    "\n",
    "ML7 = [\n",
    "    'Melody', 'Articulation', 'Rhythm Complexity', 'Rhythm Stability',\n",
    "    'Dissonance', 'Atonality', 'Mode'\n",
    "]\n",
    "\n",
    "SYM32 = [\n",
    "    'Dominants', 'Subdominants', 'sub-sub', 'sub-dom', 'dom-sub',\n",
    "    'dom-tonic', 'glob-sub', 'glob-dom', 'sub-sub-dom', 'sub-dom-sub',\n",
    "    'dom-sub-dom', 'sub-dom-tonic', 'dom-tonic-sub', 'dom-sub-sub',\n",
    "    'sub-sub-sub', 'glob-sub-glob', 'glob-dom-tonic', 'glob-sub-sub',\n",
    "    'dom-dom', 'glob-glob', 'dom-dom-sub', 'glob-glob-dom',\n",
    "    'glob-dom-glob', 'glob-glob-sub', 'dom-dom-tonic', 'glob-sub-dom',\n",
    "    'dom-tonic-dom', 'glob-dom-sub', 'sub-dom-dom', 'dom-dom-dom',\n",
    "    'glob-dom-dom', 'glob-glob-glob'\n",
    "]\n",
    "\n",
    "ALL62 = ML7 + SYM32 + E23  # full perceptual set\n",
    "\n",
    "# Feature set configurations\n",
    "FEATURE_SETS = {\n",
    "    'E23': E23,\n",
    "    'ALL62': ALL62\n",
    "}\n",
    "\n",
    "print(f\"Base path: {BASE_PATH}\")\n",
    "print(f\"Features path: {FEATURES_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")\n",
    "print(f\"\\nFeature set sizes:\")\n",
    "print(f\"  E23: {len(E23)} features\")\n",
    "print(f\"  ML7: {len(ML7)} features\")\n",
    "print(f\"  SYM32: {len(SYM32)} features\")\n",
    "print(f\"  ALL62: {len(ALL62)} features\")\n",
    "\n",
    "# Verify input files exist\n",
    "print(f\"\\nInput file verification:\")\n",
    "for name, path in INPUT_FILES.items():\n",
    "    if path.exists():\n",
    "        print(f\"✓ {name}: {path.name}\")\n",
    "    else:\n",
    "        print(f\"✗ {name}: {path.name} (NOT FOUND)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _canonicalize(s: str) -> str:\n",
    "    \"\"\"Lowercase and strip all non-alphanumerics so -, _, and spaces become equivalent.\"\"\"\n",
    "    return re.sub(r'[^a-z0-9]+', '', s.lower())\n",
    "\n",
    "def extract_base_features(expression, base_features):\n",
    "    \"\"\"\n",
    "    Robustly extract base features from an expression by canonicalizing names and\n",
    "    matching whole identifiers only (no substring hits).\n",
    "    Handles hyphen/underscore/space/CamelCase variants.\n",
    "    \"\"\"\n",
    "    if pd.isna(expression) or not expression:\n",
    "        return set()\n",
    "\n",
    "    expr_str = str(expression)\n",
    "\n",
    "    # Tokenize expression into identifiers (letters/digits with optional - or _ inside).\n",
    "    # This avoids matching across parentheses/commas/operators.\n",
    "    tokens = re.findall(r'[A-Za-z][A-Za-z0-9_-]*', expr_str)\n",
    "\n",
    "    # Precompute canonical map once per call (you can cache this externally for speed).\n",
    "    canon_map = {_canonicalize(f): f for f in base_features}\n",
    "\n",
    "    found = set()\n",
    "    for tok in tokens:\n",
    "        c = _canonicalize(tok)\n",
    "        if c in canon_map:\n",
    "            found.add(canon_map[c])\n",
    "\n",
    "    return found\n",
    "\n",
    "\n",
    "def test_feature_extraction():\n",
    "    \"\"\"\n",
    "    Test the feature extraction function with example expressions.\n",
    "    \"\"\"\n",
    "    print(\"Testing feature extraction function...\")\n",
    "    \n",
    "    test_cases = [\n",
    "        \"div(max(sub_sub_dom, glob_dom_dom), Danceability)\",\n",
    "        \"min(log(Beats_Loud), sub_sub_dom)\",\n",
    "        \"Danceability\",\n",
    "        \"sub-dom-dom\",\n",
    "        \"max(dom-sub, sub-dom)\",\n",
    "        \"div(Spectral-Centroid, BPM)|sub(Loudness, Mode)\"\n",
    "    ]\n",
    "    \n",
    "    # Test with a subset of features\n",
    "    test_features = ['Danceability', 'Beats-Loud', 'sub-sub-dom', 'glob-dom-dom', \n",
    "                     'sub-dom', 'dom-sub', 'sub-dom-dom', 'Spectral-Centroid', \n",
    "                     'BPM', 'Loudness', 'Mode']\n",
    "    \n",
    "    for i, expr in enumerate(test_cases, 1):\n",
    "        found = extract_base_features(expr, test_features)\n",
    "        print(f\"\\nTest {i}: {expr}\")\n",
    "        print(f\"Found features: {sorted(list(found))}\")\n",
    "\n",
    "# Run the test\n",
    "test_feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Co-occurrence Matrix Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_base_features(expression: str, base_features: list[str]) -> Counter:\n",
    "    \"\"\"\n",
    "    Count occurrences of each base feature in an expression.\n",
    "    Returns a Counter mapping canonicalized base-feature (original names as keys) to counts.\n",
    "    \"\"\"\n",
    "    if pd.isna(expression) or not expression:\n",
    "        return Counter()\n",
    "\n",
    "    expr_str = str(expression)\n",
    "    # identifiers like Beats_Loud, sub-sub-dom, Spectral-Centroid, BPM, etc.\n",
    "    tokens = re.findall(r'[A-Za-z][A-Za-z0-9_-]*', expr_str)\n",
    "\n",
    "    # map canonical -> original base name (prefer the given base_features' original spellings)\n",
    "    canon_to_orig = {_canonicalize(f): f for f in base_features}\n",
    "\n",
    "    counts = Counter()\n",
    "    for tok in tokens:\n",
    "        c = _canonicalize(tok)\n",
    "        if c in canon_to_orig:\n",
    "            counts[canon_to_orig[c]] += 1\n",
    "    return counts\n",
    "\n",
    "# --- Co-occurrence matrix with corrected diagonal handling ---\n",
    "\n",
    "def create_cooccurrence_matrix(df, base_features, feature_set_name):\n",
    "    \"\"\"\n",
    "    Create co-occurrence matrix for base features.\n",
    "\n",
    "    Off-diagonal: binary per expression (if both features appear, +1 to [i,j] and [j,i]).\n",
    "    Diagonal: only count repeated use; add (k-1) if a feature appears k>=2 times.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Creating Co-occurrence Matrix for {feature_set_name} ===\")\n",
    "\n",
    "    n_features = len(base_features)\n",
    "    cooccur_matrix = np.zeros((n_features, n_features), dtype=int)\n",
    "    feature_to_idx = {feature: i for i, feature in enumerate(base_features)}\n",
    "\n",
    "    total_expressions = 0\n",
    "    expressions_with_any = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        expression = row['expressions']\n",
    "        total_expressions += 1\n",
    "\n",
    "        counts = count_base_features(expression, base_features)   # counts per feature\n",
    "        if not counts:\n",
    "            continue\n",
    "\n",
    "        expressions_with_any += 1\n",
    "        present = list(counts.keys())\n",
    "\n",
    "        # Off-diagonal: binary presence (same as your original logic)\n",
    "        for i_name in present:\n",
    "            i = feature_to_idx[i_name]\n",
    "            for j_name in present:\n",
    "                j = feature_to_idx[j_name]\n",
    "                if i != j:\n",
    "                    cooccur_matrix[i, j] += 1\n",
    "\n",
    "        # Diagonal: add (k-1), remove singleton auto-counts\n",
    "        for name, k in counts.items():\n",
    "            if k >= 2:\n",
    "                i = feature_to_idx[name]\n",
    "                cooccur_matrix[i, i] += (k - 1)\n",
    "        # If k == 1, add nothing (fixes the incorrect +1 you suspected)\n",
    "\n",
    "    cooccur_df = pd.DataFrame(cooccur_matrix, index=base_features, columns=base_features)\n",
    "\n",
    "    print(f\"✓ Processed {total_expressions} expressions\")\n",
    "    print(f\"✓ {expressions_with_any} expressions contained base features\")\n",
    "    print(f\"✓ Co-occurrence matrix shape: {cooccur_df.shape}\")\n",
    "    print(f\"✓ Total co-occurrences: {cooccur_matrix.sum():,}\")\n",
    "\n",
    "    # Top off-diagonal pairs\n",
    "    top_pairs = []\n",
    "    for i in range(n_features):\n",
    "        for j in range(i+1, n_features):\n",
    "            c = cooccur_matrix[i, j]\n",
    "            if c > 0:\n",
    "                top_pairs.append((base_features[i], base_features[j], c))\n",
    "    top_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    print(f\"\\nTop 10 co-occurring feature pairs (off-diagonal):\")\n",
    "    for k, (f1, f2, c) in enumerate(top_pairs[:10], 1):\n",
    "        print(f\"  {k:2d}. {f1} + {f2}: {c} times\")\n",
    "\n",
    "    return cooccur_df\n",
    "\n",
    "# --- Performance matrix aligned with the same diagonal logic ---\n",
    "\n",
    "def create_performance_matrix(df, base_features, feature_set_name):\n",
    "    \"\"\"\n",
    "    Average test_auc for co-occurring features.\n",
    "\n",
    "    Off-diagonal: include row if both features appear (binary), count += 1, sum += test_auc.\n",
    "    Diagonal: include a row only if the feature appears k>=2 times; weight by (k-1),\n",
    "             i.e., count += (k-1), sum += test_auc * (k-1).\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Creating Performance Matrix for {feature_set_name} ===\")\n",
    "\n",
    "    n_features = len(base_features)\n",
    "    perf_sum = np.zeros((n_features, n_features), dtype=float)\n",
    "    perf_cnt = np.zeros((n_features, n_features), dtype=int)\n",
    "    feature_to_idx = {feature: i for i, feature in enumerate(base_features)}\n",
    "\n",
    "    valid_expressions = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        expression = row['expressions']\n",
    "        test_auc = row['test_auc']\n",
    "        if pd.isna(test_auc):\n",
    "            continue\n",
    "\n",
    "        counts = count_base_features(expression, base_features)\n",
    "        if not counts:\n",
    "            continue\n",
    "\n",
    "        valid_expressions += 1\n",
    "        present = list(counts.keys())\n",
    "\n",
    "        # Off-diagonal (binary)\n",
    "        for i_name in present:\n",
    "            i = feature_to_idx[i_name]\n",
    "            for j_name in present:\n",
    "                j = feature_to_idx[j_name]\n",
    "                if i != j:\n",
    "                    perf_sum[i, j] += test_auc\n",
    "                    perf_cnt[i, j] += 1\n",
    "\n",
    "        # Diagonal (k-1 weighting)\n",
    "        for name, k in counts.items():\n",
    "            if k >= 2:\n",
    "                i = feature_to_idx[name]\n",
    "                extra = k - 1\n",
    "                perf_sum[i, i] += test_auc * extra\n",
    "                perf_cnt[i, i] += extra\n",
    "        # If k == 1: do nothing (don’t include singleton rows in diagonal averages)\n",
    "\n",
    "    perf_avg = np.divide(perf_sum, perf_cnt, out=np.zeros_like(perf_sum), where=perf_cnt != 0)\n",
    "    perf_df = pd.DataFrame(perf_avg, index=base_features, columns=base_features)\n",
    "\n",
    "    print(f\"✓ Processed {valid_expressions} valid expressions with performance data\")\n",
    "    print(f\"✓ Performance matrix shape: {perf_df.shape}\")\n",
    "    print(f\"✓ Non-zero cells: {(perf_avg > 0).sum():,}\")\n",
    "\n",
    "    nz = perf_avg[perf_cnt > 0]\n",
    "    if nz.size > 0:\n",
    "        print(\"\\nPerformance statistics:\")\n",
    "        print(f\"  Mean: {nz.mean():.6f}\")\n",
    "        print(f\"  Std:  {nz.std():.6f}\")\n",
    "        print(f\"  Min:  {nz.min():.6f}\")\n",
    "        print(f\"  Max:  {nz.max():.6f}\")\n",
    "\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cooccurrence_heatmap(matrix_df, feature_set_name, dataset_name, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot co-occurrence matrix as heatmap.\n",
    "    \n",
    "    Args:\n",
    "        matrix_df (pd.DataFrame): Co-occurrence matrix\n",
    "        feature_set_name (str): Name of feature set (E23/ALL62)\n",
    "        dataset_name (str): Name of dataset (GTZAN/MTG-Jamendo)\n",
    "        save_path (Path): Path to save the plot\n",
    "    \"\"\"\n",
    "    # Calculate figure size based on number of features\n",
    "    n_features = len(matrix_df)\n",
    "    fig_size = max(12, n_features * 0.4)\n",
    "    \n",
    "    plt.figure(figsize=(fig_size, fig_size))\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = matrix_df == 0  # Mask zero values\n",
    "    \n",
    "    sns.heatmap(matrix_df, \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='YlOrRd', \n",
    "                square=True,\n",
    "                linewidths=0.1,\n",
    "                mask=mask,\n",
    "                cbar_kws={'label': 'Co-occurrence Count'})\n",
    "    \n",
    "    plt.title(f'{dataset_name} {feature_set_name}: Base Feature Co-occurrence Matrix', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Base Features', fontsize=14)\n",
    "    plt.ylabel('Base Features', fontsize=14)\n",
    "    \n",
    "    # Rotate labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Co-occurrence heatmap saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_performance_heatmap(matrix_df, feature_set_name, dataset_name, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot performance matrix as heatmap.\n",
    "    \n",
    "    Args:\n",
    "        matrix_df (pd.DataFrame): Performance matrix\n",
    "        feature_set_name (str): Name of feature set (E23/ALL62)\n",
    "        dataset_name (str): Name of dataset (GTZAN/MTG-Jamendo)\n",
    "        save_path (Path): Path to save the plot\n",
    "    \"\"\"\n",
    "    # Calculate figure size based on number of features\n",
    "    n_features = len(matrix_df)\n",
    "    fig_size = max(12, n_features * 0.4)\n",
    "    \n",
    "    plt.figure(figsize=(fig_size, fig_size))\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = matrix_df == 0  # Mask zero values\n",
    "    \n",
    "    # Get non-zero values for color scaling\n",
    "    non_zero_values = matrix_df.values[matrix_df.values > 0]\n",
    "    vmin = non_zero_values.min() if len(non_zero_values) > 0 else 0\n",
    "    vmax = non_zero_values.max() if len(non_zero_values) > 0 else 1\n",
    "    \n",
    "    sns.heatmap(matrix_df, \n",
    "                annot=True, \n",
    "                fmt='.4f', \n",
    "                cmap='RdYlBu_r', \n",
    "                square=True,\n",
    "                linewidths=0.1,\n",
    "                mask=mask,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                cbar_kws={'label': 'Average test_auc'})\n",
    "    \n",
    "    plt.title(f'{dataset_name} {feature_set_name}: Base Feature Performance Matrix', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Base Features', fontsize=14)\n",
    "    plt.ylabel('Base Features', fontsize=14)\n",
    "    \n",
    "    # Rotate labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Performance heatmap saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data and Process E23 Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load E23 data\n",
    "print(\"=\" * 80)\n",
    "print(\"PROCESSING E23 FEATURE SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    with open(INPUT_FILES['E23'], 'rb') as f:\n",
    "        e23_df = pd.read_pickle(f)\n",
    "    \n",
    "    print(f\"✓ Loaded E23 data: {len(e23_df)} rows, {len(e23_df.columns)} columns\")\n",
    "    print(f\"✓ Required columns present: {'expressions' in e23_df.columns}, {'test_auc' in e23_df.columns}\")\n",
    "    \n",
    "    if 'expressions' in e23_df.columns:\n",
    "        print(f\"\\nSample expressions:\")\n",
    "        for i, expr in enumerate(e23_df['expressions'].head(3), 1):\n",
    "            print(f\"  {i}. {expr}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading E23 data: {e}\")\n",
    "    e23_df = pd.DataFrame()\n",
    "\n",
    "if not e23_df.empty:\n",
    "    # Create co-occurrence matrix for E23\n",
    "    e23_cooccur = create_cooccurrence_matrix(e23_df, E23, 'E23')\n",
    "    \n",
    "    # Create performance matrix for E23\n",
    "    e23_performance = create_performance_matrix(e23_df, E23, 'E23')\n",
    "    \n",
    "    # Plot E23 co-occurrence heatmap\n",
    "    cooccur_save_path = OUTPUT_PATH / 'GTZAN_E23_Cooccurrence_Matrix.png'\n",
    "    plot_cooccurrence_heatmap(e23_cooccur, 'E23', 'GTZAN', cooccur_save_path)\n",
    "    \n",
    "    # Plot E23 performance heatmap\n",
    "    perf_save_path = OUTPUT_PATH / 'GTZAN_E23_Performance_Matrix.png'\n",
    "    plot_performance_heatmap(e23_performance, 'E23', 'GTZAN', perf_save_path)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping E23 analysis due to data loading issues\")\n",
    "    e23_cooccur = pd.DataFrame()\n",
    "    e23_performance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process ALL62 Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALL62 data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESSING ALL62 FEATURE SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    with open(INPUT_FILES['ALL62'], 'rb') as f:\n",
    "        all62_df = pd.read_pickle(f)\n",
    "    \n",
    "    print(f\"✓ Loaded ALL62 data: {len(all62_df)} rows, {len(all62_df.columns)} columns\")\n",
    "    print(f\"✓ Required columns present: {'expressions' in all62_df.columns}, {'test_auc' in all62_df.columns}\")\n",
    "    \n",
    "    if 'expressions' in all62_df.columns:\n",
    "        print(f\"\\nSample expressions:\")\n",
    "        for i, expr in enumerate(all62_df['expressions'].head(3), 1):\n",
    "            print(f\"  {i}. {expr}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading ALL62 data: {e}\")\n",
    "    all62_df = pd.DataFrame()\n",
    "\n",
    "if not all62_df.empty:\n",
    "    # Create co-occurrence matrix for ALL62\n",
    "    all62_cooccur = create_cooccurrence_matrix(all62_df, ALL62, 'ALL62')\n",
    "    \n",
    "    # Create performance matrix for ALL62\n",
    "    all62_performance = create_performance_matrix(all62_df, ALL62, 'ALL62')\n",
    "    \n",
    "    # Plot ALL62 co-occurrence heatmap\n",
    "    cooccur_save_path = OUTPUT_PATH / 'GTZAN_ALL62_Cooccurrence_Matrix.png'\n",
    "    plot_cooccurrence_heatmap(all62_cooccur, 'ALL62', 'GTZAN', cooccur_save_path)\n",
    "    \n",
    "    # Plot ALL62 performance heatmap\n",
    "    perf_save_path = OUTPUT_PATH / 'GTZAN_ALL62_Performance_Matrix.png'\n",
    "    plot_performance_heatmap(all62_performance, 'ALL62', 'GTZAN', perf_save_path)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping ALL62 analysis due to data loading issues\")\n",
    "    all62_cooccur = pd.DataFrame()\n",
    "    all62_performance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GTZAN EXPRESSIONS ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Output directory: {OUTPUT_PATH}\")\n",
    "\n",
    "# Summary statistics\n",
    "results_summary = []\n",
    "\n",
    "if not e23_df.empty and not e23_cooccur.empty:\n",
    "    e23_total_cooccur = e23_cooccur.values.sum()\n",
    "    e23_nonzero_cells = (e23_cooccur.values > 0).sum()\n",
    "    e23_avg_perf = e23_performance.values[e23_performance.values > 0].mean()\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Feature Set': 'E23',\n",
    "        'Input Rows': len(e23_df),\n",
    "        'Matrix Size': f'{len(E23)}x{len(E23)}',\n",
    "        'Total Co-occurrences': f'{e23_total_cooccur:,}',\n",
    "        'Active Cells': f'{e23_nonzero_cells:,}',\n",
    "        'Avg Performance': f'{e23_avg_perf:.6f}' if not np.isnan(e23_avg_perf) else 'N/A',\n",
    "        'Status': '✓ Success'\n",
    "    })\n",
    "\n",
    "if not all62_df.empty and not all62_cooccur.empty:\n",
    "    all62_total_cooccur = all62_cooccur.values.sum()\n",
    "    all62_nonzero_cells = (all62_cooccur.values > 0).sum()\n",
    "    all62_avg_perf = all62_performance.values[all62_performance.values > 0].mean()\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Feature Set': 'ALL62',\n",
    "        'Input Rows': len(all62_df),\n",
    "        'Matrix Size': f'{len(ALL62)}x{len(ALL62)}',\n",
    "        'Total Co-occurrences': f'{all62_total_cooccur:,}',\n",
    "        'Active Cells': f'{all62_nonzero_cells:,}',\n",
    "        'Avg Performance': f'{all62_avg_perf:.6f}' if not np.isnan(all62_avg_perf) else 'N/A',\n",
    "        'Status': '✓ Success'\n",
    "    })\n",
    "\n",
    "if results_summary:\n",
    "    summary_df = pd.DataFrame(results_summary)\n",
    "    print(\"\\nAnalysis Results:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "# List output files\n",
    "print(f\"\\nOutput Files Generated:\")\n",
    "output_files = list(OUTPUT_PATH.glob('GTZAN_*_Matrix.png'))\n",
    "if output_files:\n",
    "    for file_path in sorted(output_files):\n",
    "        file_size = file_path.stat().st_size\n",
    "        print(f\"  {file_path.name} ({file_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"  No matrix plots generated\")\n",
    "\n",
    "# Save matrices as CSV for further analysis\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "if not e23_cooccur.empty:\n",
    "    e23_cooccur_path = OUTPUT_PATH / f'GTZAN_E23_cooccurrence_matrix_{timestamp}.csv'\n",
    "    e23_cooccur.to_csv(e23_cooccur_path)\n",
    "    \n",
    "    e23_perf_path = OUTPUT_PATH / f'GTZAN_E23_performance_matrix_{timestamp}.csv'\n",
    "    e23_performance.to_csv(e23_perf_path)\n",
    "    \n",
    "    print(f\"\\n✓ E23 matrices saved as CSV files\")\n",
    "\n",
    "if not all62_cooccur.empty:\n",
    "    all62_cooccur_path = OUTPUT_PATH / f'GTZAN_ALL62_cooccurrence_matrix_{timestamp}.csv'\n",
    "    all62_cooccur.to_csv(all62_cooccur_path)\n",
    "    \n",
    "    all62_perf_path = OUTPUT_PATH / f'GTZAN_ALL62_performance_matrix_{timestamp}.csv'\n",
    "    all62_performance.to_csv(all62_perf_path)\n",
    "    \n",
    "    print(f\"✓ ALL62 matrices saved as CSV files\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GTZAN EXPRESSIONS ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Operation vs Base Feature Analysis\n",
    "\n",
    "This section analyzes how mathematical operations co-occur with base features.\n",
    "\n",
    "**Analysis:**\n",
    "1. Extract operations from expressions\n",
    "2. Create operation-feature co-occurrence matrix (count)\n",
    "3. Create operation-feature performance matrix (average test_auc)\n",
    "4. Generate heatmap visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all operations from the genetic programming primitive set\n",
    "OPERATIONS = [\n",
    "    'add', 'sub', 'mul', 'div', 'log', 'sqrt', 'exp', 'abs', 'inv',\n",
    "    'sin', 'cos', 'tan', 'sinh', 'cosh', 'tanh', 'pow', 'square',\n",
    "    'min', 'max', 'sigmoid', 'relu', 'lrelu', 'swish', 'if_else'\n",
    "]\n",
    "\n",
    "def extract_operations(expression):\n",
    "    \"\"\"\n",
    "    Extract operations from a GP expression.\n",
    "    \n",
    "    Args:\n",
    "        expression (str): Expression string\n",
    "    \n",
    "    Returns:\n",
    "        set: Set of operations found in the expression\n",
    "    \"\"\"\n",
    "    if pd.isna(expression) or not expression:\n",
    "        return set()\n",
    "    \n",
    "    expr_str = str(expression).strip()\n",
    "    \n",
    "    # Split by '|' to handle multiple expressions\n",
    "    expr_parts = expr_str.split('|')\n",
    "    \n",
    "    found_operations = set()\n",
    "    \n",
    "    for part in expr_parts:\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        \n",
    "        # Look for each operation in the expression\n",
    "        for op in OPERATIONS:\n",
    "            # Match operation followed by opening parenthesis\n",
    "            pattern = r'\\b' + re.escape(op) + r'\\s*\\('\n",
    "            if re.search(pattern, part):\n",
    "                found_operations.add(op)\n",
    "    \n",
    "    return found_operations\n",
    "\n",
    "\n",
    "def test_operation_extraction():\n",
    "    \"\"\"Test the operation extraction function.\"\"\"\n",
    "    print(\"Testing operation extraction function...\")\n",
    "    \n",
    "    test_cases = [\n",
    "        \"div(max(sub_sub_dom, glob_dom_dom), Danceability)\",\n",
    "        \"min(log(Beats_Loud), sub_sub_dom)\",\n",
    "        \"add(mul(Spectral_Centroid, sin(BPM)), sqrt(Loudness))\",\n",
    "        \"sigmoid(relu(Danceability))\",\n",
    "        \"if_else(sub(Mode, Atonality), pow(Length, 2), abs(Dissonance))\"\n",
    "    ]\n",
    "    \n",
    "    for i, expr in enumerate(test_cases, 1):\n",
    "        found = extract_operations(expr)\n",
    "        print(f\"\\nTest {i}: {expr}\")\n",
    "        print(f\"Found operations: {sorted(list(found))}\")\n",
    "\n",
    "# Run the test\n",
    "test_operation_extraction()\n",
    "print(f\"\\nTotal operations to analyze: {len(OPERATIONS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_operation_feature_cooccurrence_matrix(df, base_features, operations, feature_set_name):\n",
    "    \"\"\"\n",
    "    Create co-occurrence matrix: operations (rows) vs base features (columns).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'expressions' column\n",
    "        base_features (list): List of base feature names\n",
    "        operations (list): List of operation names\n",
    "        feature_set_name (str): Name of the feature set for logging\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Operation-feature co-occurrence matrix\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Creating Operation-Feature Co-occurrence Matrix for {feature_set_name} ===\")\n",
    "    \n",
    "    # Initialize matrix: operations (rows) x features (columns)\n",
    "    n_operations = len(operations)\n",
    "    n_features = len(base_features)\n",
    "    cooccur_matrix = np.zeros((n_operations, n_features), dtype=int)\n",
    "    \n",
    "    # Create mappings\n",
    "    operation_to_idx = {op: i for i, op in enumerate(operations)}\n",
    "    feature_to_idx = {feat: i for i, feat in enumerate(base_features)}\n",
    "    \n",
    "    # Process each expression\n",
    "    total_expressions = 0\n",
    "    expressions_with_content = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        expression = row['expressions']\n",
    "        total_expressions += 1\n",
    "        \n",
    "        # Extract operations and features from this expression\n",
    "        found_operations = extract_operations(expression)\n",
    "        found_features = extract_base_features(expression, base_features)\n",
    "        \n",
    "        if found_operations and found_features:\n",
    "            expressions_with_content += 1\n",
    "            \n",
    "            # Mark co-occurrences\n",
    "            for op in found_operations:\n",
    "                op_idx = operation_to_idx[op]\n",
    "                for feat in found_features:\n",
    "                    feat_idx = feature_to_idx[feat]\n",
    "                    cooccur_matrix[op_idx, feat_idx] += 1\n",
    "    \n",
    "    # Create DataFrame\n",
    "    cooccur_df = pd.DataFrame(cooccur_matrix, \n",
    "                             index=operations, \n",
    "                             columns=base_features)\n",
    "    \n",
    "    print(f\"✓ Processed {total_expressions} expressions\")\n",
    "    print(f\"✓ {expressions_with_content} expressions had both operations and features\")\n",
    "    print(f\"✓ Co-occurrence matrix shape: {cooccur_df.shape}\")\n",
    "    print(f\"✓ Total co-occurrences: {cooccur_matrix.sum():,}\")\n",
    "    \n",
    "    # Show top operation-feature pairs\n",
    "    top_pairs = []\n",
    "    for i, op in enumerate(operations):\n",
    "        for j, feat in enumerate(base_features):\n",
    "            count = cooccur_matrix[i, j]\n",
    "            if count > 0:\n",
    "                top_pairs.append((op, feat, count))\n",
    "    \n",
    "    top_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop 10 operation-feature co-occurrences:\")\n",
    "    for i, (op, feat, count) in enumerate(top_pairs[:10], 1):\n",
    "        print(f\"  {i:2d}. {op} + {feat}: {count} times\")\n",
    "    \n",
    "    return cooccur_df\n",
    "\n",
    "\n",
    "def create_operation_feature_performance_matrix(df, base_features, operations, feature_set_name):\n",
    "    \"\"\"\n",
    "    Create performance matrix: operations (rows) vs base features (columns).\n",
    "    Shows average test_auc for expressions containing each operation-feature combination.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Creating Operation-Feature Performance Matrix for {feature_set_name} ===\")\n",
    "    \n",
    "    # Initialize matrices for sum and count\n",
    "    n_operations = len(operations)\n",
    "    n_features = len(base_features)\n",
    "    perf_sum_matrix = np.zeros((n_operations, n_features), dtype=float)\n",
    "    perf_count_matrix = np.zeros((n_operations, n_features), dtype=int)\n",
    "    \n",
    "    # Create mappings\n",
    "    operation_to_idx = {op: i for i, op in enumerate(operations)}\n",
    "    feature_to_idx = {feat: i for i, feat in enumerate(base_features)}\n",
    "    \n",
    "    # Process each expression\n",
    "    valid_expressions = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        expression = row['expressions']\n",
    "        test_auc = row['test_auc']\n",
    "        \n",
    "        if pd.isna(test_auc):\n",
    "            continue\n",
    "            \n",
    "        # Extract operations and features from this expression\n",
    "        found_operations = extract_operations(expression)\n",
    "        found_features = extract_base_features(expression, base_features)\n",
    "        \n",
    "        if found_operations and found_features:\n",
    "            valid_expressions += 1\n",
    "            \n",
    "            # Add performance to co-occurrence cells\n",
    "            for op in found_operations:\n",
    "                op_idx = operation_to_idx[op]\n",
    "                for feat in found_features:\n",
    "                    feat_idx = feature_to_idx[feat]\n",
    "                    perf_sum_matrix[op_idx, feat_idx] += test_auc\n",
    "                    perf_count_matrix[op_idx, feat_idx] += 1\n",
    "    \n",
    "    # Calculate average performance\n",
    "    perf_avg_matrix = np.divide(perf_sum_matrix, perf_count_matrix, \n",
    "                               out=np.zeros_like(perf_sum_matrix), \n",
    "                               where=perf_count_matrix!=0)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    perf_df = pd.DataFrame(perf_avg_matrix, \n",
    "                          index=operations, \n",
    "                          columns=base_features)\n",
    "    \n",
    "    print(f\"✓ Processed {valid_expressions} valid expressions with performance data\")\n",
    "    print(f\"✓ Performance matrix shape: {perf_df.shape}\")\n",
    "    print(f\"✓ Non-zero cells: {(perf_avg_matrix > 0).sum():,}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    non_zero_values = perf_avg_matrix[perf_avg_matrix > 0]\n",
    "    if len(non_zero_values) > 0:\n",
    "        print(f\"\\nPerformance statistics:\")\n",
    "        print(f\"  Mean performance: {non_zero_values.mean():.6f}\")\n",
    "        print(f\"  Std performance: {non_zero_values.std():.6f}\")\n",
    "        print(f\"  Min performance: {non_zero_values.min():.6f}\")\n",
    "        print(f\"  Max performance: {non_zero_values.max():.6f}\")\n",
    "    \n",
    "    return perf_df\n",
    "\n",
    "print(\"Operation-feature matrix functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_operation_feature_heatmap(matrix_df, matrix_type, feature_set_name, dataset_name, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot operation-feature matrix as heatmap.\n",
    "    \n",
    "    Args:\n",
    "        matrix_df (pd.DataFrame): Operation-feature matrix\n",
    "        matrix_type (str): 'Cooccurrence' or 'Performance'\n",
    "        feature_set_name (str): Name of feature set (E23/ALL62)\n",
    "        dataset_name (str): Name of dataset (GTZAN/MTG-Jamendo)\n",
    "        save_path (Path): Path to save the plot\n",
    "    \"\"\"\n",
    "    # Calculate figure size\n",
    "    n_operations = len(matrix_df.index)\n",
    "    n_features = len(matrix_df.columns)\n",
    "    fig_width = max(12, n_features * 0.4)\n",
    "    fig_height = max(8, n_operations * 0.3)\n",
    "    \n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = matrix_df == 0  # Mask zero values\n",
    "    \n",
    "    if matrix_type == 'Cooccurrence':\n",
    "        sns.heatmap(matrix_df, \n",
    "                    annot=True, \n",
    "                    fmt='d', \n",
    "                    cmap='YlOrRd', \n",
    "                    linewidths=0.1,\n",
    "                    mask=mask,\n",
    "                    cbar_kws={'label': 'Co-occurrence Count'})\n",
    "    else:  # Performance\n",
    "        # Get non-zero values for color scaling\n",
    "        non_zero_values = matrix_df.values[matrix_df.values > 0]\n",
    "        vmin = non_zero_values.min() if len(non_zero_values) > 0 else 0\n",
    "        vmax = non_zero_values.max() if len(non_zero_values) > 0 else 1\n",
    "        \n",
    "        sns.heatmap(matrix_df, \n",
    "                    annot=True, \n",
    "                    fmt='.4f', \n",
    "                    cmap='RdYlBu_r', \n",
    "                    linewidths=0.1,\n",
    "                    mask=mask,\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                    cbar_kws={'label': 'Average test_auc'})\n",
    "    \n",
    "    plt.title(f'{dataset_name} {feature_set_name}: Operation-Feature {matrix_type} Matrix', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Base Features', fontsize=14)\n",
    "    plt.ylabel('Operations', fontsize=14)\n",
    "    \n",
    "    # Rotate labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Operation-feature {matrix_type.lower()} heatmap saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"Operation-feature visualization function defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Process E23 Operation-Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not e23_df.empty:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROCESSING E23 OPERATION-FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create operation-feature co-occurrence matrix for E23\n",
    "    e23_op_feat_cooccur = create_operation_feature_cooccurrence_matrix(e23_df, E23, OPERATIONS, 'E23')\n",
    "    \n",
    "    # Create operation-feature performance matrix for E23\n",
    "    e23_op_feat_performance = create_operation_feature_performance_matrix(e23_df, E23, OPERATIONS, 'E23')\n",
    "    \n",
    "    # Plot E23 operation-feature co-occurrence heatmap\n",
    "    cooccur_save_path = OUTPUT_PATH / 'GTZAN_E23_Operation_Feature_Cooccurrence_Matrix.png'\n",
    "    plot_operation_feature_heatmap(e23_op_feat_cooccur, 'Cooccurrence', 'E23', 'GTZAN', cooccur_save_path)\n",
    "    \n",
    "    # Plot E23 operation-feature performance heatmap\n",
    "    perf_save_path = OUTPUT_PATH / 'GTZAN_E23_Operation_Feature_Performance_Matrix.png'\n",
    "    plot_operation_feature_heatmap(e23_op_feat_performance, 'Performance', 'E23', 'GTZAN', perf_save_path)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping E23 operation-feature analysis due to data loading issues\")\n",
    "    e23_op_feat_cooccur = pd.DataFrame()\n",
    "    e23_op_feat_performance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Process ALL62 Operation-Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all62_df.empty:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING ALL62 OPERATION-FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create operation-feature co-occurrence matrix for ALL62\n",
    "    all62_op_feat_cooccur = create_operation_feature_cooccurrence_matrix(all62_df, ALL62, OPERATIONS, 'ALL62')\n",
    "    \n",
    "    # Create operation-feature performance matrix for ALL62\n",
    "    all62_op_feat_performance = create_operation_feature_performance_matrix(all62_df, ALL62, OPERATIONS, 'ALL62')\n",
    "    \n",
    "    # Plot ALL62 operation-feature co-occurrence heatmap\n",
    "    cooccur_save_path = OUTPUT_PATH / 'GTZAN_ALL62_Operation_Feature_Cooccurrence_Matrix.png'\n",
    "    plot_operation_feature_heatmap(all62_op_feat_cooccur, 'Cooccurrence', 'ALL62', 'GTZAN', cooccur_save_path)\n",
    "    \n",
    "    # Plot ALL62 operation-feature performance heatmap\n",
    "    perf_save_path = OUTPUT_PATH / 'GTZAN_ALL62_Operation_Feature_Performance_Matrix.png'\n",
    "    plot_operation_feature_heatmap(all62_op_feat_performance, 'Performance', 'ALL62', 'GTZAN', perf_save_path)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping ALL62 operation-feature analysis due to data loading issues\")\n",
    "    all62_op_feat_cooccur = pd.DataFrame()\n",
    "    all62_op_feat_performance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Export Operation-Feature Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPERATION-FEATURE ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save operation-feature matrices as CSV\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "if not e23_op_feat_cooccur.empty:\n",
    "    e23_op_cooccur_path = OUTPUT_PATH / f'GTZAN_E23_operation_feature_cooccurrence_{timestamp}.csv'\n",
    "    e23_op_feat_cooccur.to_csv(e23_op_cooccur_path)\n",
    "    \n",
    "    e23_op_perf_path = OUTPUT_PATH / f'GTZAN_E23_operation_feature_performance_{timestamp}.csv'\n",
    "    e23_op_feat_performance.to_csv(e23_op_perf_path)\n",
    "    \n",
    "    print(f\"✓ E23 operation-feature matrices saved as CSV files\")\n",
    "\n",
    "if not all62_op_feat_cooccur.empty:\n",
    "    all62_op_cooccur_path = OUTPUT_PATH / f'GTZAN_ALL62_operation_feature_cooccurrence_{timestamp}.csv'\n",
    "    all62_op_feat_cooccur.to_csv(all62_op_cooccur_path)\n",
    "    \n",
    "    all62_op_perf_path = OUTPUT_PATH / f'GTZAN_ALL62_operation_feature_performance_{timestamp}.csv'\n",
    "    all62_op_feat_performance.to_csv(all62_op_perf_path)\n",
    "    \n",
    "    print(f\"✓ ALL62 operation-feature matrices saved as CSV files\")\n",
    "\n",
    "# List all new output files\n",
    "print(f\"\\nNew Operation-Feature Files Generated:\")\n",
    "op_feat_files = list(OUTPUT_PATH.glob('GTZAN_*_Operation_Feature_*.png'))\n",
    "if op_feat_files:\n",
    "    for file_path in sorted(op_feat_files):\n",
    "        file_size = file_path.stat().st_size\n",
    "        print(f\"  {file_path.name} ({file_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"  No operation-feature plots generated\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPERATION-FEATURE ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _canonical_pair(a, b):\n",
    "    \"\"\"Return an unordered, deterministic pair (min, max) using string-order to avoid type issues.\"\"\"\n",
    "    return tuple(sorted((a, b), key=lambda x: str(x)))\n",
    "\n",
    "def get_top_k_cells(df: pd.DataFrame, k: int = 20, *,\n",
    "                    dropna: bool = True,\n",
    "                    keep_all_ties: bool = False,\n",
    "                    symmetric: bool = False,\n",
    "                    include_diagonal: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return top-k cells with coordinates and values.\n",
    "\n",
    "    If symmetric=True (self-matrix), (i,j) and (j,i) are treated as the same cell.\n",
    "    In that case we collapse to canonical pairs using the MAX value among duplicates\n",
    "    (robust to tiny asymmetries); results are listed with (row,col) in canonical order.\n",
    "\n",
    "    Set include_diagonal=False to exclude (i,i) cells for symmetric matrices.\n",
    "    \"\"\"\n",
    "    s = df.stack(dropna=dropna)  # MultiIndex (row, col) -> value\n",
    "    if s.empty:\n",
    "        return pd.DataFrame(columns=[\"rank\", \"row\", \"col\", \"value\"])\n",
    "\n",
    "    if not symmetric:\n",
    "        # Directional case: keep (row,col) as-is\n",
    "        s_sorted = s.sort_values(ascending=False)\n",
    "        if keep_all_ties:\n",
    "            kth_value = s_sorted.iloc[min(k, len(s_sorted)) - 1]\n",
    "            s_top = s_sorted[s_sorted >= kth_value]\n",
    "        else:\n",
    "            s_top = s_sorted.iloc[:k]\n",
    "        out = s_top.reset_index()\n",
    "        out.columns = [\"row\", \"col\", \"value\"]\n",
    "    else:\n",
    "        # Symmetric case: collapse (i,j) and (j,i) to the same canonical key\n",
    "        df_pairs = s.reset_index()\n",
    "        df_pairs.columns = [\"row\", \"col\", \"value\"]\n",
    "        if not include_diagonal:\n",
    "            df_pairs = df_pairs[df_pairs[\"row\"] != df_pairs[\"col\"]]\n",
    "\n",
    "        df_pairs[\"canon\"] = df_pairs.apply(lambda r: _canonical_pair(r[\"row\"], r[\"col\"]), axis=1)\n",
    "        # Aggregate duplicates by MAX (robust if matrix is not perfectly symmetric)\n",
    "        g = (df_pairs.groupby(\"canon\", as_index=False)\n",
    "                     .agg(value=(\"value\", \"max\")))\n",
    "\n",
    "        # Expand canon -> row, col (canonical order)\n",
    "        g[\"row\"] = g[\"canon\"].apply(lambda t: t[0])\n",
    "        g[\"col\"] = g[\"canon\"].apply(lambda t: t[1])\n",
    "\n",
    "        g = g[[\"row\", \"col\", \"value\"]].sort_values(\"value\", ascending=False)\n",
    "\n",
    "        if keep_all_ties:\n",
    "            kth_value = g[\"value\"].iloc[min(k, len(g)) - 1]\n",
    "            out = g[g[\"value\"] >= kth_value]\n",
    "        else:\n",
    "            out = g.iloc[:k]\n",
    "\n",
    "    # Dense rank: highest value => rank 1\n",
    "    out = out.copy()\n",
    "    out[\"rank\"] = out[\"value\"].rank(method=\"dense\", ascending=False).astype(int)\n",
    "    return out[[\"rank\", \"row\", \"col\", \"value\"]].sort_values([\"rank\", \"value\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compare_pair(pair_name: str, df1: pd.DataFrame, df2: pd.DataFrame, k: int = 20, *,\n",
    "                 keep_all_ties: bool = False,\n",
    "                 symmetric: bool = False,\n",
    "                 include_diagonal: bool = True,\n",
    "                 validate_same_shape: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    For one pair:\n",
    "      1) Get top-k cells in each df (respecting symmetry if needed).\n",
    "      2) Find overlapping coordinates between the two top-k lists.\n",
    "         - If symmetric=True, overlap compares unordered pairs.\n",
    "         - Otherwise, overlap compares ordered (row,col).\n",
    "    \"\"\"\n",
    "    if validate_same_shape:\n",
    "        assert set(df1.index) == set(df2.index), f\"{pair_name}: row index sets differ\"\n",
    "        assert set(df1.columns) == set(df2.columns), f\"{pair_name}: column index sets differ\"\n",
    "        if symmetric:\n",
    "            # Self-matrix sanity: same label sets on rows and cols\n",
    "            assert set(df1.index) == set(df1.columns), f\"{pair_name}: df1 not self-matrix\"\n",
    "            assert set(df2.index) == set(df2.columns), f\"{pair_name}: df2 not self-matrix\"\n",
    "\n",
    "    top1 = get_top_k_cells(df1, k=k, keep_all_ties=keep_all_ties,\n",
    "                           symmetric=symmetric, include_diagonal=include_diagonal)\n",
    "    top2 = get_top_k_cells(df2, k=k, keep_all_ties=keep_all_ties,\n",
    "                           symmetric=symmetric, include_diagonal=include_diagonal)\n",
    "\n",
    "    if not symmetric:\n",
    "        # Ordered overlap\n",
    "        overlap = top1.merge(top2, on=[\"row\", \"col\"], suffixes=(\"_df1\", \"_df2\"))\n",
    "    else:\n",
    "        # Unordered overlap via canonical key\n",
    "        t1 = top1.copy()\n",
    "        t1[\"canon\"] = t1.apply(lambda r: _canonical_pair(r[\"row\"], r[\"col\"]), axis=1)\n",
    "        t2 = top2.copy()\n",
    "        t2[\"canon\"] = t2.apply(lambda r: _canonical_pair(r[\"row\"], r[\"col\"]), axis=1)\n",
    "        overlap = t1.merge(t2, on=\"canon\", suffixes=(\"_df1\", \"_df2\"))\n",
    "        # Expand canon into row/col in canonical order for display\n",
    "        overlap[\"row\"] = overlap[\"canon\"].apply(lambda t: t[0])\n",
    "        overlap[\"col\"] = overlap[\"canon\"].apply(lambda t: t[1])\n",
    "\n",
    "    # Tidy columns and ordering\n",
    "    if \"canon\" in overlap.columns:\n",
    "        cols = [\"row\", \"col\", \"rank_df1\", \"value_df1\", \"rank_df2\", \"value_df2\"]\n",
    "        overlap = overlap[cols]\n",
    "    else:\n",
    "        overlap = overlap[[\"row\", \"col\", \"rank_df1\", \"value_df1\", \"rank_df2\", \"value_df2\"]]\n",
    "\n",
    "    overlap = overlap.sort_values([\"rank_df1\", \"rank_df2\"], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "    # Compact summary\n",
    "    print(f\"\\n=== {pair_name} ===\")\n",
    "    print(f\"Top {k} in df1: {len(top1)} rows  |  Top {k} in df2: {len(top2)} rows\")\n",
    "    print(f\"Overlap count (same {'unordered' if symmetric else 'ordered'} coordinates): {len(overlap)}\")\n",
    "    if len(overlap):\n",
    "        print(overlap.head(10).to_string(index=False))\n",
    "\n",
    "    return {\n",
    "        \"pair_name\": pair_name,\n",
    "        \"top_df1\": top1,\n",
    "        \"top_df2\": top2,\n",
    "        \"overlap\": overlap\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Apply to your four pairs\n",
    "#   Pair 1/2: directional (not symmetric)\n",
    "#   Pair 3/4: symmetric (self-matrix)  -> treat (i,j) == (j,i)\n",
    "# -------------------------\n",
    "\n",
    "K = 110\n",
    "KEEP_ALL_TIES = False\n",
    "INCLUDE_DIAGONAL = True  # set False to drop (i,i) in symmetric matrices\n",
    "\n",
    "pairs = [\n",
    "    # (name, df1, df2, symmetric?)\n",
    "    (\"pair 1: e23_op_feat (cooccur vs performance)\",     e23_op_feat_cooccur,  e23_op_feat_performance,  False),\n",
    "    (\"pair 2: all62_op_feat (cooccur vs performance)\",   all62_op_feat_cooccur, all62_op_feat_performance, False),\n",
    "    (\"pair 3: e23 (cooccur vs performance)\",             e23_cooccur,          e23_performance,          True),\n",
    "    (\"pair 4: all62 (cooccur vs performance)\",           all62_cooccur,        all62_performance,        True),\n",
    "]\n",
    "\n",
    "pair_results = {}\n",
    "for name, A, B, is_symmetric in pairs:\n",
    "    pair_results[name] = compare_pair(\n",
    "        name, A, B, k=K,\n",
    "        keep_all_ties=KEEP_ALL_TIES,\n",
    "        symmetric=is_symmetric,\n",
    "        include_diagonal=INCLUDE_DIAGONAL\n",
    "    )\n",
    "\n",
    "# Optional: save CSVs\n",
    "# for name, res in pair_results.items():\n",
    "#     tag = name.split(\":\")[0].replace(\" \", \"_\")\n",
    "#     res[\"top_df1\"].to_csv(f\"{tag}_top{K}_df1.csv\", index=False)\n",
    "#     res[\"top_df2\"].to_csv(f\"{tag}_top{K}_df2.csv\", index=False)\n",
    "#     res[\"overlap\"].to_csv(f\"{tag}_top{K}_overlap.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _canonical_pair(a, b):\n",
    "    \"\"\"Unordered, deterministic pair for symmetric matrices.\"\"\"\n",
    "    return tuple(sorted((a, b), key=lambda x: str(x)))\n",
    "\n",
    "def _rank_all_cells(df: pd.DataFrame, *, symmetric: bool, include_diagonal: bool, dropna: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute GLOBAL dense ranks (1 = highest) for ALL cells of a DataFrame.\n",
    "    If symmetric, collapse (i,j) and (j,i) using canonical pairs and keep the MAX value.\n",
    "    Returns columns: row, col, value, rank\n",
    "    \"\"\"\n",
    "    s = df.stack(dropna=dropna)  # (row,col)->value\n",
    "    if s.empty:\n",
    "        return pd.DataFrame(columns=[\"row\", \"col\", \"value\", \"rank\"])\n",
    "\n",
    "    if not symmetric:\n",
    "        out = s.reset_index()\n",
    "        out.columns = [\"row\", \"col\", \"value\"]\n",
    "    else:\n",
    "        tmp = s.reset_index()\n",
    "        tmp.columns = [\"row\", \"col\", \"value\"]\n",
    "        if not include_diagonal:\n",
    "            tmp = tmp[tmp[\"row\"] != tmp[\"col\"]]\n",
    "        tmp[\"canon\"] = tmp.apply(lambda r: _canonical_pair(r[\"row\"], r[\"col\"]), axis=1)\n",
    "        g = (tmp.groupby(\"canon\", as_index=False)\n",
    "                 .agg(value=(\"value\", \"max\")))\n",
    "        g[\"row\"] = g[\"canon\"].apply(lambda t: t[0])\n",
    "        g[\"col\"] = g[\"canon\"].apply(lambda t: t[1])\n",
    "        out = g[[\"row\", \"col\", \"value\"]]\n",
    "\n",
    "    out[\"rank\"] = out[\"value\"].rank(method=\"dense\", ascending=False).astype(int)\n",
    "    return out.sort_values([\"rank\", \"value\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "def top_m_by_df2_with_df1_rank(df1: pd.DataFrame, df2: pd.DataFrame, *,\n",
    "                               m: int = 20,\n",
    "                               symmetric: bool = False,\n",
    "                               include_diagonal: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    DF2-centric view:\n",
    "      - Take the GLOBAL top-m cells of df2 (dense rank 1..m; includes all ties at m).\n",
    "      - For each, show df1's GLOBAL rank and value at the same coordinate.\n",
    "    Works for symmetric (unordered coords) and non-symmetric (ordered) matrices.\n",
    "    Returns columns: rank_df2, row, col, value_df2, rank_df1, value_df1\n",
    "    \"\"\"\n",
    "    df1_all = _rank_all_cells(df1, symmetric=symmetric, include_diagonal=include_diagonal)\n",
    "    df2_all = _rank_all_cells(df2, symmetric=symmetric, include_diagonal=include_diagonal)\n",
    "\n",
    "    df1_all = df1_all.rename(columns={\"value\": \"value_df1\", \"rank\": \"rank_df1\"})\n",
    "    df2_all = df2_all.rename(columns={\"value\": \"value_df2\", \"rank\": \"rank_df2\"})\n",
    "\n",
    "    # Select df2's global top-m (dense ranks include ties automatically)\n",
    "    df2_top_m = df2_all[df2_all[\"rank_df2\"] <= m].copy()\n",
    "\n",
    "    # Join df1's global rank/value at same coordinates\n",
    "    out = df2_top_m.merge(df1_all, on=[\"row\", \"col\"], how=\"left\")\n",
    "\n",
    "    # Optional: add percentiles for easier reading\n",
    "    total_df1 = len(df1_all)\n",
    "    total_df2 = len(df2_all)\n",
    "    out[\"df1_percentile\"] = out[\"rank_df1\"] / total_df1  # 0 ~ best, 1 ~ worst\n",
    "    out[\"df2_percentile\"] = out[\"rank_df2\"] / total_df2\n",
    "\n",
    "    # Order by df2 priority, then df1\n",
    "    out = out[[\"rank_df2\", \"row\", \"col\", \"value_df2\", \"rank_df1\", \"value_df1\", \"df1_percentile\", \"df2_percentile\"]] \\\n",
    "           .sort_values([\"rank_df2\", \"rank_df1\"], ascending=[True, True], na_position=\"last\") \\\n",
    "           .reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# Choose m\n",
    "M = 200\n",
    "INCLUDE_DIAGONAL = True\n",
    "\n",
    "# Pair 1 (not symmetric)\n",
    "tbl_p1 = top_m_by_df2_with_df1_rank(\n",
    "    e23_op_feat_cooccur, e23_op_feat_performance,\n",
    "    m=M, symmetric=False, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Pair 2 (not symmetric)\n",
    "tbl_p2 = top_m_by_df2_with_df1_rank(\n",
    "    all62_op_feat_cooccur, all62_op_feat_performance,\n",
    "    m=M, symmetric=False, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Pair 3 (self-matrix, symmetric)\n",
    "tbl_p3 = top_m_by_df2_with_df1_rank(\n",
    "    e23_cooccur, e23_performance,\n",
    "    m=M, symmetric=True, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Pair 4 (self-matrix, symmetric)\n",
    "tbl_p4 = top_m_by_df2_with_df1_rank(\n",
    "    all62_cooccur, all62_performance,\n",
    "    m=M, symmetric=True, include_diagonal=INCLUDE_DIAGONAL\n",
    ")\n",
    "\n",
    "# Example: view first rows\n",
    "display(tbl_p2.head(55))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Improved Heatmap Visualizations\n",
    "\n",
    "This section implements enhanced heatmap visualizations with professional styling, half-diagonal layouts, and customizable options based on current best practices.\n",
    "\n",
    "**Key Improvements:**\n",
    "- Half-diagonal heatmaps combining co-occurrence and performance data\n",
    "- Professional styling with larger fonts (14pt minimum) \n",
    "- Customizable text annotations\n",
    "- Better colorbar scaling and proportions\n",
    "- Publication-ready quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import improved heatmap functions\n",
    "import sys\n",
    "sys.path.append('E:/Oxford/Extra/ICASSP/Draft_1/Codes')\n",
    "\n",
    "from improved_heatmap_functions import (\n",
    "    plot_half_diagonal_heatmap,\n",
    "    plot_combined_triangular_heatmap, \n",
    "    plot_enhanced_heatmap,\n",
    "    plot_enhanced_operation_feature_heatmap,\n",
    "    set_publication_style\n",
    ")\n",
    "\n",
    "# Set publication-ready style with larger fonts\n",
    "set_publication_style(font_size=14)\n",
    "\n",
    "print(\"✓ Improved heatmap functions imported successfully\")\n",
    "print(\"✓ Publication style set with 14pt base font size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Enhanced E23 Base Feature Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not e23_df.empty and not e23_cooccur.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENHANCED E23 BASE FEATURE VISUALIZATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Enhanced individual heatmaps with professional styling\n",
    "    print(\"\\n1. Enhanced Co-occurrence Heatmap (with text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_Cooccurrence_Matrix.png'\n",
    "    plot_enhanced_heatmap(e23_cooccur, 'Cooccurrence', 'E23', 'GTZAN', \n",
    "                          save_path=save_path, show_text=True, font_size=16)\n",
    "    \n",
    "    print(\"\\n2. Enhanced Performance Heatmap (with text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_Performance_Matrix.png'  \n",
    "    plot_enhanced_heatmap(e23_performance, 'Performance', 'E23', 'GTZAN',\n",
    "                          save_path=save_path, show_text=True, font_size=16)\n",
    "    \n",
    "    # 3. Enhanced heatmaps without text annotations (cleaner look)\n",
    "    print(\"\\n3. Enhanced Co-occurrence Heatmap (no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_Cooccurrence_NoText_Matrix.png'\n",
    "    plot_enhanced_heatmap(e23_cooccur, 'Cooccurrence', 'E23', 'GTZAN',\n",
    "                          save_path=save_path, show_text=False, font_size=16)\n",
    "    \n",
    "    print(\"\\n4. Enhanced Performance Heatmap (no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_Performance_NoText_Matrix.png'\n",
    "    plot_enhanced_heatmap(e23_performance, 'Performance', 'E23', 'GTZAN', \n",
    "                          save_path=save_path, show_text=False, font_size=16)\n",
    "    \n",
    "    # 5. Half-diagonal visualization (both upper triangles, no text)\n",
    "    print(\"\\n5. Half-Diagonal Visualization (fixed: upper triangles, no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Half_Diagonal_Matrix.png'\n",
    "    plot_half_diagonal_heatmap(e23_cooccur, e23_performance, E23, 'E23', 'GTZAN',\n",
    "                               save_path=save_path, font_size=16)\n",
    "    \n",
    "    # 6. Combined triangular heatmap (dual colorbars, no text)\n",
    "    print(\"\\n6. Combined Triangular Heatmap (fixed: dual colorbars, no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Combined_Triangular_Matrix.png'\n",
    "    plot_combined_triangular_heatmap(e23_cooccur, e23_performance, E23, 'E23', 'GTZAN',\n",
    "                                     save_path=save_path, font_size=16)\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Skipping enhanced E23 visualizations due to missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Enhanced ALL62 Base Feature Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all62_df.empty and not all62_cooccur.empty:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ENHANCED ALL62 BASE FEATURE VISUALIZATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Enhanced individual heatmaps - cleaner versions without text (recommended for ALL62)\n",
    "    print(\"\\n1. Enhanced Co-occurrence Heatmap (no text - recommended for ALL62):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_ALL62_Enhanced_Cooccurrence_Matrix.png'\n",
    "    plot_enhanced_heatmap(all62_cooccur, 'Cooccurrence', 'ALL62', 'GTZAN',\n",
    "                          save_path=save_path, show_text=False, font_size=16)\n",
    "    \n",
    "    print(\"\\n2. Enhanced Performance Heatmap (no text - recommended for ALL62):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_ALL62_Enhanced_Performance_Matrix.png'\n",
    "    plot_enhanced_heatmap(all62_performance, 'Performance', 'ALL62', 'GTZAN', \n",
    "                          save_path=save_path, show_text=False, font_size=16)\n",
    "    \n",
    "    # 2. Half-diagonal visualization (fixed: upper triangle, no text)\n",
    "    print(\"\\n3. Half-Diagonal Visualization (fixed: upper triangles, no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_ALL62_Half_Diagonal_Matrix.png'\n",
    "    plot_half_diagonal_heatmap(all62_cooccur, all62_performance, ALL62, 'ALL62', 'GTZAN',\n",
    "                               save_path=save_path, font_size=14)\n",
    "    \n",
    "    # 3. Combined triangular (fixed: dual colorbars, no text)\n",
    "    print(\"\\n4. Combined Triangular Heatmap (fixed: dual colorbars, no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_ALL62_Combined_Triangular_Matrix.png'\n",
    "    plot_combined_triangular_heatmap(all62_cooccur, all62_performance, ALL62, 'ALL62', 'GTZAN',\n",
    "                                     save_path=save_path, font_size=14)\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Skipping enhanced ALL62 visualizations due to missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Enhanced Operation-Feature Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Operation-Feature Visualizations\n",
    "print(\"\\n\" + \"=\" * 80)  \n",
    "print(\"ENHANCED OPERATION-FEATURE VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# E23 Operation-Feature Enhanced Plots\n",
    "if not e23_df.empty and 'e23_op_feat_cooccur' in globals() and not e23_op_feat_cooccur.empty:\n",
    "    print(\"\\n=== Enhanced E23 Operation-Feature Plots ===\")\n",
    "    \n",
    "    # Co-occurrence with text\n",
    "    print(\"\\n1. E23 Operation-Feature Co-occurrence (with text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_OpFeat_Cooccurrence_Matrix.png'\n",
    "    plot_enhanced_operation_feature_heatmap(e23_op_feat_cooccur, 'Cooccurrence', 'E23', 'GTZAN',\n",
    "                                           save_path=save_path, show_text=True, font_size=16)\n",
    "    \n",
    "    # Performance with text\n",
    "    print(\"\\n2. E23 Operation-Feature Performance (with text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_OpFeat_Performance_Matrix.png'\n",
    "    plot_enhanced_operation_feature_heatmap(e23_op_feat_performance, 'Performance', 'E23', 'GTZAN',\n",
    "                                           save_path=save_path, show_text=True, font_size=16)\n",
    "    \n",
    "    # Clean versions without text\n",
    "    print(\"\\n3. E23 Operation-Feature Co-occurrence (clean, no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_OpFeat_Cooccurrence_Clean_Matrix.png'\n",
    "    plot_enhanced_operation_feature_heatmap(e23_op_feat_cooccur, 'Cooccurrence', 'E23', 'GTZAN',\n",
    "                                           save_path=save_path, show_text=False, font_size=16)\n",
    "    \n",
    "    print(\"\\n4. E23 Operation-Feature Performance (clean, no text):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_E23_Enhanced_OpFeat_Performance_Clean_Matrix.png'\n",
    "    plot_enhanced_operation_feature_heatmap(e23_op_feat_performance, 'Performance', 'E23', 'GTZAN',\n",
    "                                           save_path=save_path, show_text=False, font_size=16)\n",
    "\n",
    "# ALL62 Operation-Feature Enhanced Plots (clean versions only for large matrix)\n",
    "if not all62_df.empty and 'all62_op_feat_cooccur' in globals() and not all62_op_feat_cooccur.empty:\n",
    "    print(\"\\n=== Enhanced ALL62 Operation-Feature Plots (Clean) ===\")\n",
    "    \n",
    "    print(\"\\n5. ALL62 Operation-Feature Co-occurrence (clean):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_ALL62_Enhanced_OpFeat_Cooccurrence_Matrix.png' \n",
    "    plot_enhanced_operation_feature_heatmap(all62_op_feat_cooccur, 'Cooccurrence', 'ALL62', 'GTZAN',\n",
    "                                           save_path=save_path, show_text=False, font_size=14)\n",
    "    \n",
    "    print(\"\\n6. ALL62 Operation-Feature Performance (clean):\")\n",
    "    save_path = OUTPUT_PATH / 'GTZAN_ALL62_Enhanced_OpFeat_Performance_Matrix.png'\n",
    "    plot_enhanced_operation_feature_heatmap(all62_op_feat_performance, 'Performance', 'ALL62', 'GTZAN', \n",
    "                                           save_path=save_path, show_text=False, font_size=14)\n",
    "\n",
    "print(\"\\n✓ All enhanced operation-feature visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4. Enhanced Visualizations Summary\n",
    "\n",
    "The enhanced heatmap visualizations provide several key improvements over the original plots:\n",
    "\n",
    "**Professional Styling:**\n",
    "- Larger fonts (14-16pt) for better readability\n",
    "- Improved colorbar scaling and proportions  \n",
    "- Better spacing and layout optimization\n",
    "- Publication-ready quality at 300 DPI\n",
    "\n",
    "**New Visualization Types:**\n",
    "- **Half-Diagonal Plots**: Split view showing co-occurrence and performance side-by-side\n",
    "- **Combined Triangular**: Single plot with co-occurrence below diagonal and performance above\n",
    "- **Clean Versions**: Option to hide cell text for cleaner appearance with large matrices\n",
    "\n",
    "**Customization Options:**\n",
    "- Toggleable text annotations (`show_text` parameter)\n",
    "- Adjustable font sizes\n",
    "- Custom colormaps\n",
    "- Better handling of zero values and color scaling\n",
    "\n",
    "**Space Efficiency:**\n",
    "- Compact layouts reduce redundancy in symmetric matrices\n",
    "- Better suited for publication with limited space\n",
    "- Maintains all information while reducing visual clutter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_CRM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
