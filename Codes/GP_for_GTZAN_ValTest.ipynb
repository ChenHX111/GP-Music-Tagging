{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import operator\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from functools import partial\n",
    "import traceback\n",
    "\n",
    "# DEAP imports\n",
    "from deap import algorithms, base, creator, tools, gp\n",
    "\n",
    "# ML imports\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auc(clf, x_te, x_tr, y_tr, y_te, labels, weird_probas=False):\n",
    "    global feat_set_name\n",
    "    \"\"\"Compute per‑label and mean ROC‑AUC (Jamendo / MagnaTagATune).\"\"\"\n",
    "    preds_te = clf.predict_proba(x_te)\n",
    "    preds_tr = clf.predict_proba(x_tr)\n",
    "    auc_tr, auc_te = [], []\n",
    "    for i, tag in enumerate(labels):\n",
    "        p_tr = preds_tr[:, i] if weird_probas else preds_tr[i][:, 1]\n",
    "        p_te = preds_te[:, i] if weird_probas else preds_te[i][:, 1]\n",
    "        auc_tr.append(roc_auc_score(y_tr[tag], p_tr))\n",
    "        auc_te.append(roc_auc_score(y_te[tag], p_te))\n",
    "    print(\"Mean AUC  (train):\", np.mean(auc_tr))\n",
    "    print(\"Mean AUC  (test) :\", np.mean(auc_te))\n",
    "\n",
    "    # build and return DataFrame\n",
    "    df = pd.DataFrame([{\n",
    "        'feat_set_name': feat_set_name,\n",
    "        'auc_tr': np.mean(auc_tr),\n",
    "        'auc_te': np.mean(auc_te)\n",
    "    }])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 1  Feature‑set definitions  (second cell)\n",
    "# --- Essentia 23 ‑ low/mid‑level signal descriptors ------------------\n",
    "E23 = [\n",
    "    'Danceability', 'Loudness', 'Chords-Changes-Rate', 'Dynamic-Complexity',\n",
    "    'Zerocrossingrate', 'Chords-Number-Rate', 'Pitch-Salience',\n",
    "    'Spectral-Centroid', 'Spectral-Complexity', 'Spectral-Decrease',\n",
    "    'Spectral-Energyband-High', 'Spectral-Energyband-Low',\n",
    "    'Spectral-Energyband-Middle-High', 'Spectral-Energyband-Middle-Low',\n",
    "    'Spectral-Entropy', 'Spectral-Flux', 'Spectral-Rolloff',\n",
    "    'Spectral-Spread', 'Onset-Rate', 'Length', 'BPM', 'Beats-Loud'\n",
    "]\n",
    "\n",
    "# --- Mid‑level perceptual 7 ------------------------------------------\n",
    "ML7 = [\n",
    "    'Melody', 'Articulation', 'Rhythm Complexity', 'Rhythm Stability',\n",
    "    'Dissonance', 'Atonality', 'Mode'\n",
    "]\n",
    "\n",
    "# --- Symbolic / harmony 32 -------------------------------------------\n",
    "SYM32 = [\n",
    "    'Dominants', 'Subdominants', 'sub-sub', 'sub-dom', 'dom-sub',\n",
    "    'dom-tonic', 'glob-sub', 'glob-dom', 'sub-sub-dom', 'sub-dom-sub',\n",
    "    'dom-sub-dom', 'sub-dom-tonic', 'dom-tonic-sub', 'dom-sub-sub',\n",
    "    'sub-sub-sub', 'glob-sub-glob', 'glob-dom-tonic', 'glob-sub-sub',\n",
    "    'dom-dom', 'glob-glob', 'dom-dom-sub', 'glob-glob-dom',\n",
    "    'glob-dom-glob', 'glob-glob-sub', 'dom-dom-tonic', 'glob-sub-dom',\n",
    "    'dom-tonic-dom', 'glob-dom-sub', 'sub-dom-dom', 'dom-dom-dom',\n",
    "    'glob-dom-dom', 'glob-glob-glob'\n",
    "]\n",
    "\n",
    "ALL62 = ML7 + SYM32 + E23      # full perceptual set\n",
    "\n",
    "all = ['Melody','Articulation','Rhythm Complexity','Rhythm Stability', 'Dissonance', 'Atonality', 'Mode', \n",
    "    'Dominants', 'Subdominants', 'sub-sub', 'sub-dom', 'dom-sub', 'dom-tonic', 'glob-sub',  'glob-dom', \n",
    "    'sub-sub-dom', 'sub-dom-sub', 'dom-sub-dom', 'sub-dom-tonic', 'dom-tonic-sub', \n",
    "    'dom-sub-sub', 'sub-sub-sub', 'glob-sub-glob','glob-dom-tonic', 'glob-sub-sub', 'dom-dom', 'glob-glob',  'dom-dom-sub', 'glob-glob-dom', 'glob-dom-glob', \n",
    "    'glob-glob-sub',  'dom-dom-tonic', 'glob-sub-dom',  'dom-tonic-dom',  'glob-dom-sub', 'sub-dom-dom',  'dom-dom-dom','glob-dom-dom', 'glob-glob-glob',  'Danceability','Loudness','Chords-Changes-Rate','Dynamic-Complexity','Zerocrossingrate','Chords-Number-Rate'\n",
    "    ,'Pitch-Salience','Spectral-Centroid','Spectral-Complexity','Spectral-Decrease','Spectral-Energyband-High',\n",
    "    'Spectral-Energyband-Low','Spectral-Energyband-Middle-High','Spectral-Energyband-Middle-Low','Spectral-Entropy','Spectral-Flux','Spectral-Rolloff','Spectral-Spread','Onset-Rate','Length','BPM',\n",
    "    'Beats-Loud']\n",
    "\n",
    "# 2  Global hyper‑parameters  (third cell)\n",
    "# ---------------------------------------------------------------------\n",
    "# Choose feature subset for baseline:\n",
    "#   feat_set = E23        # -> “signal‑processing only”  (M0 of E1)\n",
    "#   feat_set = ALL62      # -> full perceptual set       (M0 of E2)\n",
    "# ---------------------------------------------------------------------\n",
    "feat_set = E23       # <‑‑ change here for E1 vs E2\n",
    "if feat_set == ALL62:\n",
    "    feat_set_name = \"ALL62\"\n",
    "elif feat_set == E23:\n",
    "    feat_set_name = \"E23\"\n",
    "# xgb_params_binary = dict(\n",
    "#     max_depth=3, learning_rate=0.1, n_estimators=70,\n",
    "#     gamma=7.56, min_child_weight=6,\n",
    "#     objective='binary:logistic', eval_metric='auc'\n",
    "# )\n",
    "# xgb_params_multi = dict(\n",
    "#     max_depth=2, learning_rate=0.3, objective='multi:softmax',\n",
    "#     num_class=10, importance_type='weight'\n",
    "# )\n",
    "xgb_gpu_binary = dict(\n",
    "    tree_method='hist', device='cuda',      # use CUDA kernels  :contentReference[oaicite:2]{index=2}\n",
    "    n_estimators=70,\n",
    "    max_depth=3, learning_rate=0.1,\n",
    "    gamma=7.56, min_child_weight=6,\n",
    "    objective='binary:logistic', eval_metric='auc'\n",
    ")\n",
    "\n",
    "xgb_gpu_multi = dict(\n",
    "    tree_method='hist', device='cuda',\n",
    "    max_depth=2, learning_rate=0.3,\n",
    "    objective='multi:softmax', num_class=10,     # GTZAN   :contentReference[oaicite:4]{index=4}\n",
    "    importance_type='weight'\n",
    ")\n",
    "\n",
    "lgb_gpu_params = dict(\n",
    "    boosting_type='gbdt',\n",
    "    device='gpu',                # turn on GPU  :contentReference[oaicite:5]{index=5}\n",
    "    gpu_platform_id=-1,          # -1 -> first platform  :contentReference[oaicite:6]{index=6}\n",
    "    gpu_device_id=0,             # or pick a specific card\n",
    "    n_estimators=300,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    objective='binary',\n",
    "    metric='auc'\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 4\n",
    "DATA_ROOT = Path('D:/ICASSP1_GPMusic')   # adjust if CSVs live elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeatureGP:\n",
    "    \"\"\"\n",
    "    Multi-feature Genetic Programming for Audio Feature Engineering\n",
    "    \n",
    "    This implementation follows research best practices:\n",
    "    - Multi-tree approach for multiple feature construction\n",
    "    - Domain-specific operators for audio/music features\n",
    "    - Multi-objective fitness with complexity penalties\n",
    "    - Incremental feature addition strategy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 population_size: int = 100,\n",
    "                 generations: int = 50,\n",
    "                 max_depth: int = 6,\n",
    "                 crossover_prob: float = 0.8,\n",
    "                 mutation_prob: float = 0.05,\n",
    "                 tournament_size: int = 3,\n",
    "                 complexity_weight: float = 0.01,\n",
    "                 elite_size: int = 5,\n",
    "                 random_state: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize GP with research-backed hyperparameters\n",
    "        \n",
    "        Args:\n",
    "            population_size: 50-200 optimal for audio tasks (research: 75-100 for music)\n",
    "            generations: 25-50 sufficient for convergence\n",
    "            max_depth: 5-8 optimal balance (research shows 6 works well)\n",
    "            crossover_prob: 0.8-0.9 optimal (research: 0.8-0.9)\n",
    "            mutation_prob: 0.02-0.05 for audio (research: lower for feature selection)\n",
    "            tournament_size: 3-5 consistently outperforms alternatives\n",
    "            complexity_weight: 0.001-0.1 of accuracy weight\n",
    "            elite_size: 3-5% of population for preservation\n",
    "            random_state: For reproducibility\n",
    "        \"\"\"\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.max_depth = max_depth\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.mutation_prob = mutation_prob\n",
    "        self.tournament_size = tournament_size\n",
    "        self.complexity_weight = complexity_weight\n",
    "        self.elite_size = elite_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.history = []       # will hold per-individual dicts\n",
    "        self.save_path = None   # filled in by caller before .fit()\n",
    "        \n",
    "        # Initialize random state\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        # Storage for results and features\n",
    "        self.best_features = []\n",
    "        self.feature_expressions = []\n",
    "        self.evolution_log = []\n",
    "        self.baseline_results = None\n",
    "        \n",
    "        # Feature construction tracking\n",
    "        self.constructed_features_data = None\n",
    "        self.feature_correlations = {}\n",
    "\n",
    "    def benchmark_classifiers(self, X_val: np.ndarray, y_val: np.ndarray, \n",
    "                            X_test: np.ndarray, y_test: np.ndarray,\n",
    "                            xgb_params: dict, n_trials: int = 10) -> Dict:\n",
    "        \"\"\"\n",
    "        Benchmark Random Forest vs GPU XGBoost for fitness evaluation speed\n",
    "        \n",
    "        Args:\n",
    "            X_val, y_val: Validation data for testing\n",
    "            X_test, y_test: Test data for testing  \n",
    "            xgb_params: Your xgb_gpu_binary parameters\n",
    "            n_trials: Number of trials to average over\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with timing results and recommendations\n",
    "        \"\"\"\n",
    "        import time\n",
    "        \n",
    "        print(\"🏁 BENCHMARKING CLASSIFIERS FOR FITNESS EVALUATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create dummy feature for testing (single feature like in GP evaluation)\n",
    "        dummy_feature_val = np.random.randn(X_val.shape[0], 1)\n",
    "        dummy_feature_test = np.random.randn(X_test.shape[0], 1)\n",
    "        \n",
    "        # Test Random Forest\n",
    "        print(\"Testing Random Forest...\")\n",
    "        rf_times = []\n",
    "        rf_aucs_val = []\n",
    "        rf_aucs_test = []\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            clf_rf = RandomForestClassifier(n_estimators=50, random_state=self.random_state, n_jobs=1)\n",
    "            auc_scores_val = []\n",
    "            auc_scores_test = []\n",
    "            \n",
    "            for i in range(y_val.shape[1]):\n",
    "                try:\n",
    "                    clf_rf.fit(dummy_feature_val, y_val[:, i])\n",
    "                    \n",
    "                    # Validation AUC\n",
    "                    y_pred_proba_val = clf_rf.predict_proba(dummy_feature_val)[:, 1]\n",
    "                    auc_val = roc_auc_score(y_val[:, i], y_pred_proba_val)\n",
    "                    auc_scores_val.append(auc_val)\n",
    "                    \n",
    "                    # Test AUC  \n",
    "                    y_pred_proba_test = clf_rf.predict_proba(dummy_feature_test)[:, 1]\n",
    "                    auc_test = roc_auc_score(y_test[:, i], y_pred_proba_test)\n",
    "                    auc_scores_test.append(auc_test)\n",
    "                except:\n",
    "                    auc_scores_val.append(0.5)\n",
    "                    auc_scores_test.append(0.5)\n",
    "            \n",
    "            rf_times.append(time.time() - start_time)\n",
    "            rf_aucs_val.append(np.mean(auc_scores_val))\n",
    "            rf_aucs_test.append(np.mean(auc_scores_test))\n",
    "        \n",
    "        # Test XGBoost\n",
    "        print(\"Testing GPU XGBoost...\")\n",
    "        xgb_times = []\n",
    "        xgb_aucs_val = []\n",
    "        xgb_aucs_test = []\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "            model_xgb.fit(dummy_feature_val, y_val)\n",
    "            \n",
    "            # Predictions\n",
    "            val_pred_proba = model_xgb.predict_proba(dummy_feature_val)\n",
    "            test_pred_proba = model_xgb.predict_proba(dummy_feature_test)\n",
    "            \n",
    "            # Calculate AUCs\n",
    "            auc_scores_val = []\n",
    "            auc_scores_test = []\n",
    "            for i in range(y_val.shape[1]):\n",
    "                try:\n",
    "                    proba_val = val_pred_proba[i][:, 1] if len(val_pred_proba[i].shape) > 1 else val_pred_proba[i]\n",
    "                    proba_test = test_pred_proba[i][:, 1] if len(test_pred_proba[i].shape) > 1 else test_pred_proba[i]\n",
    "                    \n",
    "                    auc_val = roc_auc_score(y_val[:, i], proba_val)\n",
    "                    auc_test = roc_auc_score(y_test[:, i], proba_test)\n",
    "                    \n",
    "                    auc_scores_val.append(auc_val)\n",
    "                    auc_scores_test.append(auc_test)\n",
    "                except:\n",
    "                    auc_scores_val.append(0.5)\n",
    "                    auc_scores_test.append(0.5)\n",
    "            \n",
    "            xgb_times.append(time.time() - start_time)\n",
    "            xgb_aucs_val.append(np.mean(auc_scores_val))\n",
    "            xgb_aucs_test.append(np.mean(auc_scores_test))\n",
    "        \n",
    "        # Calculate statistics\n",
    "        rf_mean_time = np.mean(rf_times)\n",
    "        rf_std_time = np.std(rf_times)\n",
    "        xgb_mean_time = np.mean(xgb_times)\n",
    "        xgb_std_time = np.std(xgb_times)\n",
    "        \n",
    "        speedup = xgb_mean_time / rf_mean_time\n",
    "        \n",
    "        print(f\"\\n📊 BENCHMARK RESULTS ({n_trials} trials):\")\n",
    "        print(f\"Random Forest: {rf_mean_time:.3f}±{rf_std_time:.3f}s per evaluation\")\n",
    "        print(f\"GPU XGBoost:   {xgb_mean_time:.3f}±{xgb_std_time:.3f}s per evaluation\")\n",
    "        print(f\"Speedup factor: {speedup:.2f}x ({'RF faster' if speedup > 1 else 'XGB faster'})\")\n",
    "        \n",
    "        print(f\"\\n📈 Performance comparison:\")\n",
    "        print(f\"Random Forest Val AUC: {np.mean(rf_aucs_val):.4f}±{np.std(rf_aucs_val):.4f}\")\n",
    "        print(f\"GPU XGBoost Val AUC:   {np.mean(xgb_aucs_val):.4f}±{np.std(xgb_aucs_val):.4f}\")\n",
    "        print(f\"Random Forest Test AUC: {np.mean(rf_aucs_test):.4f}±{np.std(rf_aucs_test):.4f}\")\n",
    "        print(f\"GPU XGBoost Test AUC:   {np.mean(xgb_aucs_test):.4f}±{np.std(xgb_aucs_test):.4f}\")\n",
    "        \n",
    "        # Recommendation\n",
    "        if speedup > 1.5:\n",
    "            recommendation = \"Use Random Forest for GP fitness evaluation (significantly faster)\"\n",
    "        elif speedup < 0.67:\n",
    "            recommendation = \"Use GPU XGBoost for GP fitness evaluation (significantly faster)\"\n",
    "        else:\n",
    "            recommendation = \"Both methods have similar speed - choose based on performance quality\"\n",
    "        \n",
    "        print(f\"\\n💡 RECOMMENDATION: {recommendation}\")\n",
    "        \n",
    "        # Estimate total GP time\n",
    "        total_evaluations = self.population_size * self.generations * 5  # Rough estimate\n",
    "        rf_total_time = total_evaluations * rf_mean_time / 3600  # Hours\n",
    "        xgb_total_time = total_evaluations * xgb_mean_time / 3600  # Hours\n",
    "        \n",
    "        print(f\"\\n⏱️  Estimated total GP time (5 features):\")\n",
    "        print(f\"With Random Forest: {rf_total_time:.1f} hours\")\n",
    "        print(f\"With GPU XGBoost:   {xgb_total_time:.1f} hours\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return {\n",
    "            'rf_mean_time': rf_mean_time,\n",
    "            'rf_std_time': rf_std_time,\n",
    "            'xgb_mean_time': xgb_mean_time,\n",
    "            'xgb_std_time': xgb_std_time,\n",
    "            'speedup': speedup,\n",
    "            'recommendation': recommendation,\n",
    "            'rf_val_auc': np.mean(rf_aucs_val),\n",
    "            'xgb_val_auc': np.mean(xgb_aucs_val),\n",
    "            'rf_test_auc': np.mean(rf_aucs_test),\n",
    "            'xgb_test_auc': np.mean(xgb_aucs_test)\n",
    "        }\n",
    "\n",
    "\n",
    "    def setup_primitive_set(self, feature_names: List[str]) -> gp.PrimitiveSet:\n",
    "        \"\"\"\n",
    "        Create domain-specific primitive set for audio feature engineering\n",
    "        \n",
    "        Based on research, effective audio primitives include:\n",
    "        - Arithmetic operators for combining spectral features\n",
    "        - Statistical operations for temporal aggregation\n",
    "        - Trigonometric functions for periodic analysis\n",
    "        - Boolean operations for threshold-based features\n",
    "        \"\"\"\n",
    "        # Create primitive set with feature inputs\n",
    "        pset = gp.PrimitiveSet(\"MAIN\", len(feature_names))\n",
    "        \n",
    "        # Rename arguments to feature names for interpretability\n",
    "        for i, name in enumerate(feature_names):\n",
    "            pset.renameArguments(**{f'ARG{i}': name.replace(' ', '_').replace('-', '_')})\n",
    "        \n",
    "        # Arithmetic operators - essential for combining spectral features\n",
    "        pset.addPrimitive(operator.add, 2, name=\"add\")\n",
    "        pset.addPrimitive(operator.sub, 2, name=\"sub\") \n",
    "        pset.addPrimitive(operator.mul, 2, name=\"mul\")\n",
    "        \n",
    "        # Protected division to avoid division by zero\n",
    "        def protectedDiv(left, right):\n",
    "            return left / right if abs(right) > 1e-6 else 1.0\n",
    "        pset.addPrimitive(protectedDiv, 2, name=\"div\")\n",
    "        \n",
    "        # Statistical operators - crucial for temporal aggregation in audio\n",
    "        def safe_log(x):\n",
    "            return np.log(abs(x) + 1e-6)\n",
    "        pset.addPrimitive(safe_log, 1, name=\"log\")\n",
    "        \n",
    "        def safe_sqrt(x):\n",
    "            return np.sqrt(abs(x))\n",
    "        pset.addPrimitive(safe_sqrt, 1, name=\"sqrt\")\n",
    "        \n",
    "        def safe_exp(x):\n",
    "            return np.exp(np.clip(x, -500, 500))  # Prevent overflow\n",
    "        pset.addPrimitive(safe_exp, 1, name=\"exp\")\n",
    "\n",
    "        # Added: Absolute Value\n",
    "        pset.addPrimitive(np.abs, 1, name=\"abs\")\n",
    "        \n",
    "        # Added: Inverse (protected)\n",
    "        def protected_inv(x):\n",
    "            return 1.0 / x if abs(x) > 1e-6 else 0.0\n",
    "        pset.addPrimitive(protected_inv, 1, name=\"inv\")\n",
    "        \n",
    "        # Trigonometric functions - valuable for periodic signal analysis\n",
    "        pset.addPrimitive(np.sin, 1, name=\"sin\")\n",
    "        pset.addPrimitive(np.cos, 1, name=\"cos\")\n",
    "\n",
    "        # Added: tan, sinh, cosh, tanh\n",
    "        def protected_tan(x):\n",
    "            # tan(x) approaches infinity at odd multiples of pi/2.\n",
    "            # We'll protect against values very close to these points.\n",
    "            # A common approach is to return a large but finite number or 0.\n",
    "            if abs(np.cos(x)) < 1e-6: # Check if cos(x) is near zero\n",
    "                return 0.0 # Or some large finite number like 1e6 or -1e6\n",
    "            return np.tan(x)\n",
    "        pset.addPrimitive(protected_tan, 1, name=\"tan\")\n",
    "        \n",
    "        pset.addPrimitive(np.sinh, 1, name=\"sinh\")\n",
    "        pset.addPrimitive(np.cosh, 1, name=\"cosh\")\n",
    "        pset.addPrimitive(np.tanh, 1, name=\"tanh\")\n",
    "        \n",
    "        # Power functions for nonlinear combinations\n",
    "        def safe_power(x, y):\n",
    "            try:\n",
    "                if x == 0:\n",
    "                    return 0\n",
    "                return np.power(abs(x), abs(y) % 3 + 1)  # Limit exponent to prevent overflow\n",
    "            except:\n",
    "                return 1.0\n",
    "        pset.addPrimitive(safe_power, 2, name=\"pow\")\n",
    "\n",
    "        # Added: square\n",
    "        def square(x):\n",
    "            return x * x\n",
    "        pset.addPrimitive(square, 1, name=\"square\")\n",
    "        \n",
    "        # Min/Max operations for feature selection and thresholding\n",
    "        pset.addPrimitive(min, 2, name=\"min\")\n",
    "        pset.addPrimitive(max, 2, name=\"max\")\n",
    "\n",
    "        # Neural Network Activation Functions\n",
    "        # Sigmoid (Logistic)\n",
    "        def sigmoid(x):\n",
    "            # Clip input to prevent overflow in np.exp for large negative x\n",
    "            return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "        pset.addPrimitive(sigmoid, 1, name=\"sigmoid\")\n",
    "\n",
    "        # ReLU (Rectified Linear Unit)\n",
    "        def relu(x):\n",
    "            return np.maximum(0, x)\n",
    "        pset.addPrimitive(relu, 1, name=\"relu\")\n",
    "\n",
    "        # Leaky ReLU\n",
    "        def leaky_relu(x, alpha=0.01):\n",
    "            return np.where(x > 0, x, alpha * x)\n",
    "        # Note: For Leaky ReLU, if you want 'alpha' to be a trainable/fixed hyperparameter,\n",
    "        # you'd need a different approach than a simple primitive.\n",
    "        # Here, alpha is fixed to 0.01.\n",
    "        pset.addPrimitive(leaky_relu, 1, name=\"lrelu\")\n",
    "\n",
    "        # Swish (Sigmoid-weighted linear unit) - requires multiplication\n",
    "        # This one is a bit more complex as it's x * sigmoid(x)\n",
    "        def swish(x):\n",
    "            return x * (1 / (1 + np.exp(-np.clip(x, -500, 500))))\n",
    "        pset.addPrimitive(swish, 1, name=\"swish\")\n",
    "        \n",
    "        # Conditional operations for threshold-based features\n",
    "        def if_then_else(condition, output1, output2):\n",
    "            return output1 if condition > 0 else output2\n",
    "        pset.addPrimitive(if_then_else, 3, name=\"if_else\")\n",
    "        \n",
    "        # Add ephemeral constants\n",
    "        pset.addEphemeralConstant(\"rand\", lambda: random.uniform(-2, 2))\n",
    "        \n",
    "        return pset\n",
    "        \n",
    "    def setup_deap_toolbox(self, pset: gp.PrimitiveSet, \n",
    "                           X_train: np.ndarray, y_train: np.ndarray,\n",
    "                          X_val: np.ndarray, y_val: np.ndarray,\n",
    "                          X_test: np.ndarray = None, y_test: np.ndarray = None,\n",
    "                          use_xgboost: bool = False, xgb_params: dict = None) -> base.Toolbox:\n",
    "        \"\"\"\n",
    "        Configure DEAP toolbox with fitness function and genetic operators\n",
    "        \n",
    "        Uses multi-objective fitness balancing AUC performance with complexity penalty\n",
    "        Research shows this approach prevents bloat while maintaining performance\n",
    "        \n",
    "        Args:\n",
    "            pset: Primitive set for GP\n",
    "            X_val, y_val: Validation data for fitness evaluation\n",
    "            X_test, y_test: Optional test data for monitoring (not used in fitness)\n",
    "            use_xgboost: Whether to use XGBoost instead of Random Forest\n",
    "            xgb_params: XGBoost parameters if use_xgboost=True\n",
    "        \"\"\"\n",
    "        # Create fitness and individual classes\n",
    "        # Maximize AUC, minimize complexity (negative for maximization)\n",
    "        creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0))\n",
    "        creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMulti)\n",
    "        \n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        # Expression generation with controlled depth\n",
    "        toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
    "        toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        \n",
    "        # Compilation function\n",
    "        toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "        \n",
    "        # Store test performance for monitoring (not used in fitness)\n",
    "        self.test_performance_log = []\n",
    "        \n",
    "        # Fitness evaluation with multi-objective approach\n",
    "        def evaluate_fitness(individual, X_train, y_train, X_val, y_val, X_test=None, y_test=None):\n",
    "            try:\n",
    "                # 1) compile GP tree to function\n",
    "                func = toolbox.compile(expr=individual)\n",
    "\n",
    "                # 2) produce new feature on val set\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    f_train_raw = np.array([func(*row) for row in X_train]).reshape(-1,1)\n",
    "                    f_val_raw = np.array([func(*row) for row in X_val]).reshape(-1,1)\n",
    "                    # --- Perform the non-finite check for both train and val raw data ---\n",
    "                    if np.any(~np.isfinite(f_train_raw)) or np.any(~np.isfinite(f_val_raw)):\n",
    "                        raise ValueError(\"Invalid feature values (NaN or Inf) detected in raw training or validation data.\")\n",
    "                    scaler = StandardScaler().fit(np.vstack((f_train_raw, f_val_raw)))\n",
    "                    fv_train = scaler.transform(f_train_raw)\n",
    "                    fv_val = scaler.transform(f_val_raw)\n",
    "\n",
    "                    # --- CLEAN NaN, Inf, and clip extremes ---\n",
    "                    fv_train = np.nan_to_num(fv_train, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "                    fv_val   = np.nan_to_num(fv_val,   nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "                    # optional test feature (for monitoring)\n",
    "                    fv_test_s = None\n",
    "                    if X_test is not None and y_test is not None:\n",
    "                        try:\n",
    "                            ft = np.array([func(*row) for row in X_test]).reshape(-1,1)\n",
    "                            fv_test_s = scaler.transform(ft)\n",
    "                        except:\n",
    "                            fv_test_s = None\n",
    "\n",
    "                # 3) combine with originals\n",
    "                X_train_comb = np.hstack([X_train, fv_train])\n",
    "                X_val_comb   = np.hstack([X_val,   fv_val])\n",
    "                if fv_test_s is not None:\n",
    "                    X_test_comb = np.hstack([X_test, fv_test_s])\n",
    "\n",
    "                # 1) Collapse any one-hot labels into class indices:\n",
    "                if y_train.ndim > 1:\n",
    "                    # Multi-class with one-hot: convert to single integer per sample\n",
    "                    y_train_s = np.argmax(y_train, axis=1)\n",
    "                    y_val_s   = np.argmax(y_val,   axis=1)\n",
    "                    y_test_s  = np.argmax(y_test,  axis=1) if y_test is not None else None\n",
    "                else:\n",
    "                    # Already 1D labels\n",
    "                    y_train_s, y_val_s, y_test_s = y_train, y_val, y_test\n",
    "\n",
    "                # 5) train & score\n",
    "                if use_xgboost and xgb_params:\n",
    "                    clf = xgb.XGBClassifier(**xgb_params, missing=0.0)\n",
    "                else:\n",
    "                    clf = RandomForestClassifier(\n",
    "                                n_estimators=50,\n",
    "                                random_state=self.random_state,\n",
    "                                n_jobs=1)\n",
    "                clf.fit(X_train_comb, y_train_s)\n",
    "\n",
    "                # — compute TRAIN AUC —\n",
    "                acc_tr = accuracy_score(y_train_s, clf.predict(X_train_comb))\n",
    "                individual.train_auc = acc_tr\n",
    "\n",
    "                # 5) score on VALIDATION split\n",
    "                acc_val = accuracy_score(y_val_s, clf.predict(X_val_comb))\n",
    "                mean_val_auc = acc_val\n",
    "                individual.val_auc = acc_val\n",
    "\n",
    "                # 6) optional TEST monitoring\n",
    "                if fv_test_s is not None:\n",
    "                    acc_test = accuracy_score(y_test_s, clf.predict(X_test_comb))\n",
    "                    individual.test_auc = acc_test\n",
    "\n",
    "                # — extract GP-feature importances —\n",
    "                if hasattr(clf, \"estimators_\"):\n",
    "                    # Multi-output: average importances across sub-estimators\n",
    "                    imps    = np.stack([est.feature_importances_ for est in clf.estimators_])\n",
    "                    avg_imp = imps.mean(axis=0)\n",
    "                else:\n",
    "                    # Single-label: direct feature_importances_ array\n",
    "                    avg_imp = clf.feature_importances_\n",
    "\n",
    "                # original feature count = X_train.shape[1]\n",
    "                gp_imp = avg_imp[X_train.shape[1]:]\n",
    "                individual.gp_importances = gp_imp.tolist()\n",
    "\n",
    "                # complexity penalty is tree size\n",
    "                complexity = len(individual)\n",
    "\n",
    "                return mean_val_auc, complexity\n",
    "\n",
    "            except Exception as e:\n",
    "                # 1) Print the exception message\n",
    "                print(f\"[evaluate_fitness] Caught exception: {e}\")\n",
    "\n",
    "                # 2) Print full traceback for debugging\n",
    "                traceback.print_exc()\n",
    "                \n",
    "                # 3) Fallback to worst fitness\n",
    "                individual.train_auc = 0.0\n",
    "                individual.val_auc   = 0.0\n",
    "                individual.test_auc  = 0.0\n",
    "                individual.gp_importances = []\n",
    "                return 0.0, len(individual)\n",
    "        \n",
    "        toolbox.register(\"evaluate\", evaluate_fitness, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, \n",
    "                        X_test=X_test, y_test=y_test)\n",
    "        \n",
    "        # Selection and genetic operators based on research recommendations\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=self.tournament_size)\n",
    "        toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "        toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "        toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "        \n",
    "        # Restrict tree depth to prevent bloat\n",
    "        toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=self.max_depth))\n",
    "        toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=self.max_depth))\n",
    "        \n",
    "        return toolbox\n",
    "    \n",
    "    def check_feature_correlation(self, new_feature: np.ndarray, \n",
    "                                existing_features: np.ndarray, threshold: float = 0.95) -> bool:\n",
    "        \"\"\"\n",
    "        Check if new feature is too correlated with existing features\n",
    "        Research shows correlation-based redundancy management prevents duplicate features\n",
    "        \"\"\"\n",
    "        if existing_features.shape[1] == 0:\n",
    "            return False\n",
    "            \n",
    "        correlations = [abs(np.corrcoef(new_feature, existing_features[:, i])[0, 1]) \n",
    "                       for i in range(existing_features.shape[1])]\n",
    "        max_correlation = max(correlations) if correlations else 0\n",
    "        \n",
    "        return max_correlation > threshold\n",
    "    \n",
    "    def evolve_single_feature(self, feature_idx, X_train: np.ndarray, y_train: np.ndarray,\n",
    "                            X_val: np.ndarray, y_val: np.ndarray,\n",
    "                            X_test: np.ndarray, y_test: np.ndarray,\n",
    "                            existing_features: np.ndarray,\n",
    "                            feature_names: List[str],\n",
    "                            use_xgboost: bool = False, \n",
    "                            xgb_params: dict = None) -> Tuple[Any, Dict]:\n",
    "        \"\"\"\n",
    "        Evolve a single new feature using GP\n",
    "        \n",
    "        Returns best individual and evolution statistics\n",
    "        \"\"\"\n",
    "        print(f\"Initializing GP with {len(feature_names)} input features...\")\n",
    "        \n",
    "        # Setup GP components\n",
    "        pset = self.setup_primitive_set(feature_names)\n",
    "        toolbox = self.setup_deap_toolbox(pset, X_train, y_train, X_val, y_val, X_test, y_test, use_xgboost, xgb_params)\n",
    "        \n",
    "        # Create initial population\n",
    "        print(f\"Creating initial population of {self.population_size} individuals...\")\n",
    "        population = toolbox.population(n=self.population_size)\n",
    "        \n",
    "        # Evaluate initial population\n",
    "        print(\"Evaluating initial population...\")\n",
    "        fitnesses = list(map(toolbox.evaluate, population))\n",
    "        for ind, fit in zip(population, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            # log it\n",
    "            self.history.append({\n",
    "                'phase':  'init',\n",
    "                'feature_round': feature_idx+1,\n",
    "                'generation':     0,\n",
    "                'expression':     str(ind),\n",
    "                'train_auc':      getattr(ind, 'train_auc', None),\n",
    "                'val_auc':        getattr(ind, 'val_auc',   None),\n",
    "                'test_auc':       getattr(ind, 'test_auc',  None),\n",
    "                'gp_importances': getattr(ind, 'gp_importances', [])\n",
    "            })\n",
    "        \n",
    "        # Initial population statistics\n",
    "        initial_auc_scores = [ind.fitness.values[0] for ind in population]\n",
    "        initial_complexities = [ind.fitness.values[1] for ind in population]\n",
    "        initial_test_aucs = [getattr(ind, 'test_auc', None) for ind in population]\n",
    "        initial_test_aucs = [auc for auc in initial_test_aucs if auc is not None]\n",
    "        \n",
    "        print(f\"Initial population stats:\")\n",
    "        print(f\"  Val AUC: min={min(initial_auc_scores):.4f}, max={max(initial_auc_scores):.4f}, \"\n",
    "              f\"avg={np.mean(initial_auc_scores):.4f}, std={np.std(initial_auc_scores):.4f}\")\n",
    "        if initial_test_aucs:\n",
    "            print(f\"  Test AUC: min={min(initial_test_aucs):.4f}, max={max(initial_test_aucs):.4f}, \"\n",
    "                  f\"avg={np.mean(initial_test_aucs):.4f}, std={np.std(initial_test_aucs):.4f}\")\n",
    "        print(f\"  Complexity: min={min(initial_complexities):.1f}, max={max(initial_complexities):.1f}, \"\n",
    "              f\"avg={np.mean(initial_complexities):.1f}\")\n",
    "        \n",
    "        # Show best initial individual\n",
    "        best_initial = tools.selBest(population, 1)[0]\n",
    "        initial_test_auc = getattr(best_initial, 'test_auc', 'N/A')\n",
    "        print(f\"  Best initial: Val AUC={best_initial.fitness.values[0]:.4f}, \"\n",
    "              f\"Test AUC={initial_test_auc if initial_test_auc != 'N/A' else 'N/A':.4f}, \"\n",
    "              f\"Complexity={best_initial.fitness.values[1]:.1f}\")\n",
    "        print(f\"  Expression: {str(best_initial)}\")\n",
    "        \n",
    "        # Evolution statistics\n",
    "        stats_auc = tools.Statistics(lambda ind: ind.fitness.values[0])  # Track validation AUC\n",
    "        stats_auc.register(\"avg\", np.mean)\n",
    "        stats_auc.register(\"max\", np.max)\n",
    "        stats_auc.register(\"min\", np.min)\n",
    "        stats_auc.register(\"std\", np.std)\n",
    "        \n",
    "        stats_complexity = tools.Statistics(lambda ind: ind.fitness.values[1])  # Track complexity\n",
    "        stats_complexity.register(\"avg\", np.mean)\n",
    "        stats_complexity.register(\"max\", np.max)\n",
    "        stats_complexity.register(\"min\", np.min)\n",
    "        \n",
    "        # Test AUC statistics (for monitoring)\n",
    "        def get_test_auc(ind):\n",
    "            return getattr(ind, 'test_auc', 0.5)  # Default to random if not available\n",
    "        stats_test = tools.Statistics(get_test_auc)\n",
    "        stats_test.register(\"avg\", np.mean)\n",
    "        stats_test.register(\"max\", np.max)\n",
    "        stats_test.register(\"min\", np.min)\n",
    "        \n",
    "        logbook = tools.Logbook()\n",
    "        logbook.header = ['gen', 'nevals', 'val_avg', 'val_max', 'val_min', 'val_std', \n",
    "                         'test_avg', 'test_max', 'test_min', 'comp_avg', 'comp_max', 'comp_min']\n",
    "        \n",
    "        print(f\"\\nStarting evolution for {self.generations} generations...\")\n",
    "        print(\"Gen | Nevals | Val_avg  | Val_max  | Test_avg | Test_max | Val-Test | Comp_avg | Best_expr\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        stagnation_counter = 0\n",
    "        best_fitness_ever = -1.0\n",
    "        \n",
    "        # Evolution loop\n",
    "        for generation in range(self.generations):\n",
    "            # Select next generation\n",
    "            offspring = toolbox.select(population, len(population) - self.elite_size)\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover and mutation\n",
    "            crossover_count = 0\n",
    "            mutation_count = 0\n",
    "            \n",
    "            # Apply crossover and mutation\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.crossover_prob:\n",
    "                    toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "                    crossover_count += 2\n",
    "            \n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.mutation_prob:\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "                    mutation_count += 1\n",
    "            \n",
    "            # Evaluate new individuals\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "\n",
    "                # *** ADD THIS BLOCK: log each re-evaluated individual ***\n",
    "                self.history.append({\n",
    "                    'phase':         'eval',\n",
    "                    'feature_round': feature_idx+1,\n",
    "                    'last_feature_exp': self.feature_expressions[-1] if self.feature_expressions else None,\n",
    "                    'generation':    generation+1,\n",
    "                    'expression':    str(ind),\n",
    "                    'train_auc':     getattr(ind, 'train_auc', None),\n",
    "                    'val_auc':       getattr(ind, 'val_auc',   None),\n",
    "                    'test_auc':      getattr(ind, 'test_auc',  None),\n",
    "                    'gp_importances':getattr(ind, 'gp_importances', [])\n",
    "                })\n",
    "            \n",
    "            # Elite preservation - keep best individuals\n",
    "            elite = tools.selBest(population, self.elite_size)\n",
    "            population[:] = offspring + elite\n",
    "            \n",
    "            # Record statistics\n",
    "            record_val = stats_auc.compile(population)\n",
    "            record_complexity = stats_complexity.compile(population)\n",
    "            record_test = stats_test.compile(population)\n",
    "            \n",
    "            logbook.record(gen=generation, nevals=len(invalid_ind), \n",
    "                          val_avg=record_val['avg'], val_max=record_val['max'], \n",
    "                          val_min=record_val['min'], val_std=record_val['std'],\n",
    "                          test_avg=record_test['avg'], test_max=record_test['max'],\n",
    "                          test_min=record_test['min'],\n",
    "                          comp_avg=record_complexity['avg'], comp_max=record_complexity['max'],\n",
    "                          comp_min=record_complexity['min'])\n",
    "            \n",
    "            # Get current best individual\n",
    "            current_best = tools.selBest(population, 1)[0]\n",
    "            current_best_val_auc = current_best.fitness.values[0]\n",
    "            current_best_test_auc = getattr(current_best, 'test_auc', None)\n",
    "            \n",
    "            # Check for improvement\n",
    "            if current_best_val_auc > best_fitness_ever:\n",
    "                best_fitness_ever = current_best_val_auc\n",
    "                stagnation_counter = 0\n",
    "                improvement_marker = \" ✓\"\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "                improvement_marker = \"\"\n",
    "            \n",
    "            # Calculate validation-test gap for overfitting monitoring\n",
    "            val_test_gap = record_val['max'] - record_test['max'] if record_test['max'] > 0 else 0\n",
    "            \n",
    "            # Progress display every generation\n",
    "            print(f\"{generation:3d} | {len(invalid_ind):6d} | {record_val['avg']:8.4f} | \"\n",
    "                  f\"{record_val['max']:8.4f} | {record_test['avg']:8.4f} | {record_test['max']:8.4f} | \"\n",
    "                  f\"{val_test_gap:8.4f} | {record_complexity['avg']:8.1f} | \"\n",
    "                  f\"{str(current_best)[:20]}...{improvement_marker}\")\n",
    "\n",
    "            df_hist = pd.DataFrame(self.history)\n",
    "            df_hist.to_csv(self.save_path / 'dark_gp_individual_history.csv', index=False)\n",
    "            df_hist.to_pickle(self.save_path / 'dark_gp_individual_history.pkl')\n",
    "            \n",
    "            # Detailed stats every 10 generations\n",
    "            if (generation + 1) % 10 == 0:\n",
    "                print(f\"\\n--- Generation {generation + 1} Detailed Stats ---\")\n",
    "                print(f\"Population diversity: {len(set(str(ind) for ind in population))} unique individuals\")\n",
    "                print(f\"Genetic operations: {crossover_count} crossovers, {mutation_count} mutations\")\n",
    "                print(f\"Stagnation count: {stagnation_counter}\")\n",
    "                print(f\"Current best expression: {str(current_best)}\")\n",
    "                # Build a safe string for test AUC\n",
    "                test_auc_str = (f\"{current_best_test_auc:.4f}\"\n",
    "                                if current_best_test_auc is not None\n",
    "                                else \"N/A\")\n",
    "                print(\n",
    "                    f\"Current best fitness: Val AUC={current_best.fitness.values[0]:.4f}, \"\n",
    "                    f\"Test AUC={test_auc_str}, \"\n",
    "                    f\"Complexity={current_best.fitness.values[1]:.1f}\"\n",
    "                )\n",
    "                \n",
    "                # Show top 3 individuals with test performance\n",
    "                top_3 = tools.selBest(population, 3)\n",
    "                print(\"Top 3 individuals:\")\n",
    "                for i, ind in enumerate(top_3):\n",
    "                    test_auc = getattr(ind, 'test_auc', None)\n",
    "                    # Pre‑compute per‑individual test‑AUC string\n",
    "                    indiv_test_str = (f\"{test_auc:.4f}\"\n",
    "                                      if test_auc is not None\n",
    "                                      else \"N/A\")\n",
    "                    print(\n",
    "                        f\"  {i+1}. Val AUC={ind.fitness.values[0]:.4f}, \"\n",
    "                        f\"Test AUC={indiv_test_str}, \"\n",
    "                        f\"Complexity={ind.fitness.values[1]:.1f}, \"\n",
    "                        f\"Expr={str(ind)[:40]}...\"\n",
    "                    )\n",
    "                \n",
    "                # Overfitting warning\n",
    "                if val_test_gap > 0.05:\n",
    "                    print(f\"⚠️  WARNING: Large val-test gap ({val_test_gap:.4f}) - possible overfitting!\")\n",
    "                print()\n",
    "            \n",
    "            # Early stopping conditions\n",
    "            if generation > 10 and stagnation_counter >= 15:\n",
    "                print(f\"\\nEarly stopping at generation {generation} (no improvement for 15 generations)\")\n",
    "                break\n",
    "                \n",
    "            if generation > 5 and len(logbook) > 5:\n",
    "                recent_max = [logbook[i]['val_max'] for i in range(-5, 0)]\n",
    "                if max(recent_max) - min(recent_max) < 0.0001:\n",
    "                    print(f\"\\nEarly stopping at generation {generation} (convergence detected)\")\n",
    "                    break\n",
    "        \n",
    "        # Final evolution summary\n",
    "        print(f\"\\n--- Evolution Complete ---\")\n",
    "        print(f\"Generations run: {generation + 1}\")\n",
    "        print(f\"Final population diversity: {len(set(str(ind) for ind in population))}\")\n",
    "        \n",
    "        # Return best individual and evolution info\n",
    "        best_individual = tools.selBest(population, 1)[0]\n",
    "        best_test_auc = getattr(best_individual, 'test_auc', None)\n",
    "        \n",
    "        print(f\"Best individual found:\")\n",
    "        print(f\"  Val AUC: {best_individual.fitness.values[0]:.4f}\")\n",
    "        best_test_auc_str = f\"{best_test_auc:.4f}\" if best_test_auc is not None else \"N/A\"\n",
    "        print(f\"Test AUC: {best_test_auc_str}\")\n",
    "        print(f\"  Complexity: {best_individual.fitness.values[1]:.1f}\")\n",
    "        print(f\"  Expression: {str(best_individual)}\")\n",
    "        \n",
    "        evolution_info = {\n",
    "            'generations_run': generation + 1,\n",
    "            'final_fitness': best_individual.fitness.values,\n",
    "            'final_test_auc': best_test_auc,\n",
    "            'population_diversity': len(set(str(ind) for ind in population)),\n",
    "            'logbook': logbook,\n",
    "            'stagnation_counter': stagnation_counter,\n",
    "            'improvement_generations': [i for i, record in enumerate(logbook) \n",
    "                                      if i == 0 or record['val_max'] > logbook[i-1]['val_max']]\n",
    "        }\n",
    "        \n",
    "        return best_individual, evolution_info\n",
    "    \n",
    "    def construct_feature_from_individual(self, individual: Any, \n",
    "                                        X: np.ndarray, feature_names: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Construct actual feature values from GP individual\n",
    "        \"\"\"\n",
    "        pset = self.setup_primitive_set(feature_names)\n",
    "        func = gp.compile(individual, pset)\n",
    "        \n",
    "        try:\n",
    "            feature_values = np.array([func(*row) for row in X])\n",
    "            \n",
    "            # Handle invalid values\n",
    "            if np.any(~np.isfinite(feature_values)):\n",
    "                feature_values = np.nan_to_num(feature_values, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "            \n",
    "            return feature_values\n",
    "        except Exception as e:\n",
    "            print(f\"Error constructing feature: {e}\")\n",
    "            return np.zeros(X.shape[0])\n",
    "    \n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray,\n",
    "            X_val: np.ndarray, y_val: np.ndarray,\n",
    "            X_test: np.ndarray, y_test: np.ndarray,\n",
    "            feature_names: List[str],\n",
    "            max_features: int = 5,\n",
    "            baseline_results: pd.DataFrame = None,\n",
    "            use_xgboost: bool = False,\n",
    "            xgb_params: dict = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Main fitting method implementing iterative feature construction\n",
    "        \n",
    "        Args:\n",
    "            X_train, y_train: Training data\n",
    "            X_val, y_val: Validation data for fitness evaluation\n",
    "            X_test, y_test: Test data for final evaluation and monitoring\n",
    "            feature_names: Names of original features\n",
    "            max_features: Maximum number of GP features to construct\n",
    "            baseline_results: Baseline model results for comparison\n",
    "            use_xgboost: Whether to use XGBoost instead of Random Forest for fitness\n",
    "            xgb_params: XGBoost parameters if use_xgboost=True\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with comprehensive results\n",
    "        \"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"🎵 STARTING MULTI-FEATURE GP EVOLUTION FOR AUDIO FEATURES 🎵\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"📊 Dataset Info:\")\n",
    "        print(f\"   Training samples: {X_train.shape[0]}\")\n",
    "        print(f\"   Validation samples: {X_val.shape[0]}\")\n",
    "        print(f\"   Test samples: {X_test.shape[0]}\")\n",
    "        print(f\"   Original features: {X_train.shape[1]}\")\n",
    "        # print(f\"   Target labels: {y_train.shape[1]}\")\n",
    "        print(f\"🔧 GP Parameters:\")\n",
    "        print(f\"   Population size: {self.population_size}\")\n",
    "        print(f\"   Max generations: {self.generations}\")\n",
    "        print(f\"   Max tree depth: {self.max_depth}\")\n",
    "        print(f\"   Crossover prob: {self.crossover_prob}\")\n",
    "        print(f\"   Mutation prob: {self.mutation_prob}\")\n",
    "        print(f\"   Complexity weight: {self.complexity_weight}\")\n",
    "        print(f\"   Target GP features: {max_features}\")\n",
    "        print(f\"   Fitness classifier: {'GPU XGBoost' if use_xgboost else 'Random Forest'}\")\n",
    "        \n",
    "        if baseline_results is not None:\n",
    "            baseline_train_auc = baseline_results['acc_tr'].iloc[0]\n",
    "            baseline_test_auc = baseline_results['acc_te'].iloc[0]\n",
    "            print(f\"📈 Baseline Performance:\")\n",
    "            print(f\"   Train AUC: {baseline_train_auc:.4f}\")\n",
    "            print(f\"   Test AUC: {baseline_test_auc:.4f}\")\n",
    "            print(f\"   Target: Beat {baseline_test_auc:.4f} on test set\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        self.baseline_results = baseline_results\n",
    "        \n",
    "        # Initialize feature storage\n",
    "        gp_features_train = np.empty((X_train.shape[0], 0))\n",
    "        gp_features_val = np.empty((X_val.shape[0], 0))\n",
    "        gp_features_test = np.empty((X_test.shape[0], 0))\n",
    "        \n",
    "        all_results = []\n",
    "        feature_construction_log = []\n",
    "        \n",
    "        # Iterative feature construction\n",
    "        for feature_idx in range(max_features):\n",
    "            print(f\"\\n🧬 EVOLVING FEATURE {feature_idx + 1}/{max_features}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Track time for this feature\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Evolve new feature\n",
    "            best_individual, evolution_info = self.evolve_single_feature(\n",
    "                feature_idx, X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                gp_features_val, feature_names, use_xgboost, xgb_params\n",
    "            )\n",
    "            \n",
    "            evolution_time = time.time() - start_time\n",
    "            print(f\"⏱️  Evolution completed in {evolution_time:.1f} seconds\")\n",
    "            \n",
    "            # Construct feature values\n",
    "            print(\"🔨 Constructing feature values for all datasets...\")\n",
    "            new_feature_train = self.construct_feature_from_individual(\n",
    "                best_individual, X_train, feature_names)\n",
    "            new_feature_val = self.construct_feature_from_individual(\n",
    "                best_individual, X_val, feature_names)\n",
    "            new_feature_test = self.construct_feature_from_individual(\n",
    "                best_individual, X_test, feature_names)\n",
    "            \n",
    "            # Feature quality checks\n",
    "            print(\"🔍 Feature quality checks:\")\n",
    "            print(f\"   Train: min={np.min(new_feature_train):.3f}, max={np.max(new_feature_train):.3f}, \"\n",
    "                  f\"mean={np.mean(new_feature_train):.3f}, std={np.std(new_feature_train):.3f}\")\n",
    "            print(f\"   NaN/Inf values: {np.sum(~np.isfinite(new_feature_train))}\")\n",
    "            \n",
    "            # Check correlation with existing features\n",
    "            if self.check_feature_correlation(new_feature_val, gp_features_val):\n",
    "                print(f\"❌ Feature {feature_idx + 1} too correlated with existing features (>0.95), skipping...\")\n",
    "                feature_construction_log.append({\n",
    "                    'feature_idx': feature_idx + 1,\n",
    "                    'status': 'rejected_correlation',\n",
    "                    'expression': str(best_individual),\n",
    "                    'fitness': best_individual.fitness.values,\n",
    "                    'evolution_time': evolution_time\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Add new feature\n",
    "            gp_features_train = np.column_stack([gp_features_train, new_feature_train])\n",
    "            gp_features_val = np.column_stack([gp_features_val, new_feature_val])\n",
    "            gp_features_test = np.column_stack([gp_features_test, new_feature_test])\n",
    "            \n",
    "            # Store feature expression for interpretability\n",
    "            feature_expression = str(best_individual)\n",
    "            self.feature_expressions.append(feature_expression)\n",
    "            print(f\"✅ Feature {feature_idx + 1} ACCEPTED!\")\n",
    "            print(f\"   Expression: {feature_expression}\")\n",
    "            \n",
    "            # Evaluate current feature set\n",
    "            print(f\"📊 Evaluating feature set with {len(self.feature_expressions)} GP features...\")\n",
    "            results = self.evaluate_feature_set(\n",
    "                X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                gp_features_train, gp_features_val, gp_features_test,\n",
    "                len(self.feature_expressions), evolution_info\n",
    "            )\n",
    "            \n",
    "            all_results.append(results)\n",
    "            \n",
    "            # Performance summary\n",
    "            print(f\"🎯 Performance Results:\")\n",
    "            print(f\"   Training AUC:   {results['train_auc']:.4f} (Δ{results['train_diff']:+.4f})\")\n",
    "            print(f\"   Validation AUC: {results['val_auc']:.4f} (Δ{results['val_diff']:+.4f})\")\n",
    "            print(f\"   Test AUC:       {results['test_auc']:.4f} (Δ{results['test_diff']:+.4f})\")\n",
    "            \n",
    "            if results['test_diff'] > 0:\n",
    "                print(f\"   🎉 IMPROVEMENT! Test AUC increased by {results['test_diff']:.4f}\")\n",
    "            elif results['test_diff'] > -0.01:\n",
    "                print(f\"   😐 Marginal change in test AUC ({results['test_diff']:+.4f})\")\n",
    "            else:\n",
    "                print(f\"   😞 Test AUC decreased by {abs(results['test_diff']):.4f}\")\n",
    "            \n",
    "            feature_construction_log.append({\n",
    "                'feature_idx': feature_idx + 1,\n",
    "                'status': 'accepted',\n",
    "                'expression': feature_expression,\n",
    "                'fitness': best_individual.fitness.values,\n",
    "                'evolution_time': evolution_time,\n",
    "                'results': results\n",
    "            })\n",
    "            \n",
    "            # Performance tracking across features\n",
    "            if len(all_results) >= 2:\n",
    "                val_trend = results['val_auc'] - all_results[-2]['val_auc']\n",
    "                test_trend = results['test_auc'] - all_results[-2]['test_auc']\n",
    "                print(f\"   📈 Trends: Val AUC {val_trend:+.4f}, Test AUC {test_trend:+.4f}\")\n",
    "            \n",
    "            # Early stopping conditions\n",
    "            if len(all_results) >= 3:\n",
    "                recent_val_aucs = [r['val_auc'] for r in all_results[-3:]]\n",
    "                val_improvement = max(recent_val_aucs) - min(recent_val_aucs)\n",
    "                \n",
    "                if val_improvement < 0.001:\n",
    "                    print(f\"\\n🛑 EARLY STOPPING: No significant validation improvement in last 3 features\")\n",
    "                    print(f\"   (improvement < 0.001: {val_improvement:.6f})\")\n",
    "                    break\n",
    "            \n",
    "            # Check if we're overfitting\n",
    "            if results['train_auc'] - results['test_auc'] > 0.1:\n",
    "                print(f\"⚠️  WARNING: Large train-test gap ({results['train_auc'] - results['test_auc']:.4f})\")\n",
    "                print(f\"   Consider reducing complexity or stopping feature construction\")\n",
    "            \n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Store final results\n",
    "        self.constructed_features_data = {\n",
    "            'train': gp_features_train,\n",
    "            'val': gp_features_val, \n",
    "            'test': gp_features_test\n",
    "        }\n",
    "        \n",
    "        # Final summary\n",
    "        print(f\"\\n🏁 GP FEATURE CONSTRUCTION COMPLETE!\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"📈 Summary:\")\n",
    "        print(f\"   Features constructed: {len(self.feature_expressions)}\")\n",
    "        print(f\"   Features attempted: {len(feature_construction_log)}\")\n",
    "        \n",
    "        if all_results:\n",
    "            best_iteration = max(all_results, key=lambda x: x['val_auc'])\n",
    "            final_iteration = all_results[-1]\n",
    "            \n",
    "            print(f\"🥇 Best Performance (Feature {best_iteration['num_gp_features']}):\")\n",
    "            print(f\"   Validation AUC: {best_iteration['val_auc']:.4f} (Δ{best_iteration['val_diff']:+.4f})\")\n",
    "            print(f\"   Test AUC: {best_iteration['test_auc']:.4f} (Δ{best_iteration['test_diff']:+.4f})\")\n",
    "            \n",
    "            print(f\"📊 Final Performance:\")\n",
    "            print(f\"   Validation AUC: {final_iteration['val_auc']:.4f} (Δ{final_iteration['val_diff']:+.4f})\")\n",
    "            print(f\"   Test AUC: {final_iteration['test_auc']:.4f} (Δ{final_iteration['test_diff']:+.4f})\")\n",
    "            \n",
    "            if baseline_results is not None:\n",
    "                if final_iteration['test_diff'] > 0:\n",
    "                    print(f\"   🎉 SUCCESS! Improved test AUC by {final_iteration['test_diff']:.4f}\")\n",
    "                else:\n",
    "                    print(f\"   😞 No improvement over baseline\")\n",
    "        \n",
    "        print(f\"🧬 Constructed Features:\")\n",
    "        for i, expr in enumerate(self.feature_expressions):\n",
    "            print(f\"   GP_Feature_{i+1}: {expr}\")\n",
    "        \n",
    "        final_results = {\n",
    "            'all_iterations': all_results,\n",
    "            'best_iteration': max(all_results, key=lambda x: x['val_auc']) if all_results else None,\n",
    "            'feature_expressions': self.feature_expressions,\n",
    "            'total_features_constructed': len(self.feature_expressions),\n",
    "            'construction_log': feature_construction_log\n",
    "        }\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return final_results\n",
    "    \n",
    "    def evaluate_feature_set(self, X_train: np.ndarray, y_train: np.ndarray,\n",
    "                           X_val: np.ndarray, y_val: np.ndarray,\n",
    "                           X_test: np.ndarray, y_test: np.ndarray,\n",
    "                           gp_features_train: np.ndarray, gp_features_val: np.ndarray,\n",
    "                           gp_features_test: np.ndarray,\n",
    "                           num_gp_features: int, evolution_info: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate current feature set with comprehensive metrics\n",
    "        \"\"\"\n",
    "        # Combine original and GP features\n",
    "        X_train_combined = np.column_stack([X_train, gp_features_train])\n",
    "        X_val_combined = np.column_stack([X_val, gp_features_val])\n",
    "        X_test_combined = np.column_stack([X_test, gp_features_test])\n",
    "\n",
    "        # --- Concatenate, fit scaler, and transform both arrays ---\n",
    "        scaler = StandardScaler().fit(np.vstack((X_train_combined, X_val_combined)))\n",
    "        X_train_combined_s = scaler.transform(X_train_combined)\n",
    "        X_val_combined_s = scaler.transform(X_val_combined)\n",
    "        X_test_combined_s = scaler.transform(X_test_combined)\n",
    "        \n",
    "        # Train model with combined features\n",
    "        model = xgb.XGBClassifier(**xgb_gpu_multi)\n",
    "        \n",
    "        \n",
    "        model.fit(X_train_combined, y_train)\n",
    "        \n",
    "        train_auc = accuracy_score(y_train, model.predict(X_train_combined_s))\n",
    "        val_auc = accuracy_score(y_val, model.predict(X_val_combined_s))\n",
    "        test_auc = accuracy_score(y_test, model.predict(X_test_combined_s))\n",
    "        \n",
    "        # Calculate improvements over baseline\n",
    "        train_diff = test_diff = val_diff = 0.0\n",
    "        if self.baseline_results is not None:\n",
    "            baseline_train_auc = self.baseline_results['acc_tr'].iloc[0]\n",
    "            baseline_test_auc = self.baseline_results['acc_te'].iloc[0]\n",
    "            train_diff = train_auc - baseline_train_auc\n",
    "            test_diff = test_auc - baseline_test_auc\n",
    "            val_diff = val_auc - baseline_test_auc  # Compare val to baseline test\n",
    "        \n",
    "        results = {\n",
    "            'num_gp_features': num_gp_features,\n",
    "            'train_auc': train_auc,\n",
    "            'val_auc': val_auc,\n",
    "            'test_auc': test_auc,\n",
    "            'train_diff': train_diff,\n",
    "            'val_diff': val_diff,\n",
    "            'test_diff': test_diff,\n",
    "            'generations_run': evolution_info['generations_run'],\n",
    "            'final_fitness': evolution_info['final_fitness'],\n",
    "            'population_diversity': evolution_info['population_diversity'],\n",
    "            'feature_expressions': self.feature_expressions.copy()\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results(self, results: Dict, save_path: Path):\n",
    "        \"\"\"Save comprehensive results to disk\"\"\"\n",
    "        # Convert results to DataFrame for easier analysis\n",
    "        iterations_data = []\n",
    "        for iteration in results['all_iterations']:\n",
    "            iterations_data.append({\n",
    "                'num_gp_features': iteration['num_gp_features'],\n",
    "                'train_auc': iteration['train_auc'],\n",
    "                'val_auc': iteration['val_auc'], \n",
    "                'test_auc': iteration['test_auc'],\n",
    "                'train_diff': iteration['train_diff'],\n",
    "                'val_diff': iteration['val_diff'],\n",
    "                'test_diff': iteration['test_diff'],\n",
    "                'generations_run': iteration['generations_run'],\n",
    "                'population_diversity': iteration['population_diversity'],\n",
    "                'feature_expression': iteration['feature_expressions'][-1] if iteration['feature_expressions'] else \"\"\n",
    "            })\n",
    "        \n",
    "        df_results = pd.DataFrame(iterations_data)\n",
    "        \n",
    "        # Save results\n",
    "        df_results.to_csv(save_path / 'dark_gp_feature_evolution_results.csv', index=False)\n",
    "        df_results.to_pickle(save_path / 'dark_gp_feature_evolution_results.pkl')\n",
    "        \n",
    "        # Save complete results object\n",
    "        with open(save_path / 'dark_gp_complete_results.pkl', 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        \n",
    "        # Save constructed features\n",
    "        if self.constructed_features_data:\n",
    "            np.savez(save_path / 'dark_gp_constructed_features.npz',\n",
    "                    train=self.constructed_features_data['train'],\n",
    "                    val=self.constructed_features_data['val'],\n",
    "                    test=self.constructed_features_data['test'])\n",
    "        \n",
    "        print(f\"Results saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with your data\n",
    "def run_gp_feature_engineering(DATA_ROOT, feat_set, xgb_gpu_binary, benchmark_first: bool = True):\n",
    "    \"\"\"\n",
    "    Complete pipeline for GP feature engineering on your Jamendo dataset\n",
    "    \n",
    "    Args:\n",
    "        DATA_ROOT: Path to your data\n",
    "        feat_set: List of feature names\n",
    "        xgb_gpu_binary: Your XGBoost GPU parameters\n",
    "        benchmark_first: Whether to run classifier benchmark before GP evolution\n",
    "    \"\"\"\n",
    "    \n",
    "    # ---------------------- GTZAN (single‑label 10 genres) ----------------\n",
    "    gtzan_csv = DATA_ROOT / 'GTZAN/Ref_Perceptual_features/perceptual_features.csv'\n",
    "    df = pd.read_csv(gtzan_csv).drop(columns=['Track'])\n",
    "\n",
    "    # rename to match your other splits\n",
    "    df.rename(columns={'dom': 'Dominants', 'sub': 'Subdominants'}, inplace=True)\n",
    "\n",
    "    X = df[feat_set]\n",
    "    y_onehot = df.drop(columns=all)        # the 10 one‑hot genre cols\n",
    "    genre_labels = y_onehot.columns.tolist()\n",
    "\n",
    "    # convert one‑hot → integer labels\n",
    "    y_int = y_onehot.values.argmax(axis=1)\n",
    "\n",
    "    # 1) Split off test (20%)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y_int,\n",
    "        train_size=0.8,\n",
    "        random_state=4\n",
    "    )\n",
    "\n",
    "    # 2) From the 80% “temp”, split out validation (20% of temp → 16% overall)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=0.2,\n",
    "        # stratify=y_temp,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # Optional scaling (recommended)\n",
    "    scaler = StandardScaler().fit(X_temp)\n",
    "    x_tr_scaled = scaler.transform(X_train)\n",
    "    x_val_scaled = scaler.transform(X_val)\n",
    "    x_te_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Split training data for GP (use validation split for GP fitness evaluation)\n",
    "    x_train_gp = x_tr_scaled\n",
    "    y_train_gp = y_train\n",
    "    x_val_gp = x_val_scaled\n",
    "    y_val_gp = y_val\n",
    "    x_test_gp = x_te_scaled\n",
    "    y_test_gp = y_test\n",
    "\n",
    "    gtzan_xgb = xgb.XGBClassifier(**xgb_gpu_multi).fit(x_train_gp,y_train_gp)\n",
    "    print(\"XGB train acc:\", accuracy_score(y_train_gp, gtzan_xgb.predict(x_train_gp)))\n",
    "    print(\"XGB test  acc:\", accuracy_score(y_test_gp, gtzan_xgb.predict(x_test_gp)))\n",
    "\n",
    "    # Load baseline results for comparison\n",
    "    try:\n",
    "        df_GTZAN_xgb = pd.read_pickle(DATA_ROOT / f'GTZAN/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.pkl')\n",
    "        print(f\"Loaded baseline results: Train AUC = {df_GTZAN_xgb['acc_tr'].iloc[0]:.4f}, \"\n",
    "              f\"Test AUC = {df_GTZAN_xgb['acc_te'].iloc[0]:.4f}\")\n",
    "    except:\n",
    "        print(\"Baseline results not found, will run without comparison\")\n",
    "        df_GTZAN_xgb = None\n",
    "\n",
    "    # Initialize GP\n",
    "    gp_engineer = AudioFeatureGP(\n",
    "        population_size=100,    # Research-backed for music tasks\n",
    "        generations=50,         # Sufficient for convergence\n",
    "        max_depth=6,           # Optimal balance\n",
    "        crossover_prob=0.8,    # Research optimum\n",
    "        mutation_prob=0.1,    # Good for feature construction\n",
    "        complexity_weight=0.01, # Prevent bloat\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Optional: Benchmark classifiers first\n",
    "    use_xgboost = True # False # Set to False if benchmark_first is true\n",
    "    if benchmark_first:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"🏁 BENCHMARKING CLASSIFIERS FIRST...\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        benchmark_results = gp_engineer.benchmark_classifiers(\n",
    "            x_val_gp, y_val_gp, x_test_gp, y_test_gp, xgb_gpu_binary, n_trials=5\n",
    "        )\n",
    "        \n",
    "        # Use the faster method\n",
    "        use_xgboost = benchmark_results['speedup'] < 1.0  # XGB faster if speedup < 1\n",
    "        classifier_name = \"GPU XGBoost\" if use_xgboost else \"Random Forest\"\n",
    "        print(f\"\\n🚀 Using {classifier_name} for GP fitness evaluation\")\n",
    "        \n",
    "        if use_xgboost:\n",
    "            print(\"⚠️  Note: Using XGBoost may be slower but potentially more accurate\")\n",
    "        else:\n",
    "            print(\"⚡ Using Random Forest for faster evolution\")\n",
    "\n",
    "    # Run GP feature engineering\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"🧬 STARTING GP FEATURE ENGINEERING\")\n",
    "    print(f\"Classifier: {'GPU XGBoost' if use_xgboost else 'Random Forest'}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    gp_engineer.save_path = DATA_ROOT / f'GTZAN/Ref_Perceptual_features/dark_{feat_set_name}_gensize500'\n",
    "    results = gp_engineer.fit(\n",
    "        X_train=x_train_gp,\n",
    "        y_train=y_train_gp,\n",
    "        X_val=x_val_gp,\n",
    "        y_val=y_val_gp,\n",
    "        X_test=x_test_gp,\n",
    "        y_test=y_test_gp,\n",
    "        feature_names=feat_set,\n",
    "        max_features=5,  # Construct up to 5 GP features\n",
    "        baseline_results=df_GTZAN_xgb,\n",
    "        use_xgboost=use_xgboost,\n",
    "        xgb_params=xgb_gpu_multi if use_xgboost else None\n",
    "    )\n",
    "\n",
    "    # Save results\n",
    "    gp_engineer.save_results(results, gp_engineer.save_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🎉 GP FEATURE ENGINEERING COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Best validation AUC improvement: {results['best_iteration']['val_diff']:.4f}\")\n",
    "    print(f\"Best test AUC improvement: {results['best_iteration']['test_diff']:.4f}\")\n",
    "    print(f\"Features constructed: {results['total_features_constructed']}\")\n",
    "    \n",
    "    if benchmark_first:\n",
    "        print(f\"\\nBenchmark summary:\")\n",
    "        print(f\"  Random Forest: {benchmark_results['rf_mean_time']:.3f}s per evaluation\")\n",
    "        print(f\"  GPU XGBoost:   {benchmark_results['xgb_mean_time']:.3f}s per evaluation\")\n",
    "        print(f\"  Used: {classifier_name}\")\n",
    "    \n",
    "    return gp_engineer, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GP feature engineering\n",
    "gp_engineer, results = run_gp_feature_engineering(DATA_ROOT, feat_set, xgb_gpu_binary, benchmark_first=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_CRM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
