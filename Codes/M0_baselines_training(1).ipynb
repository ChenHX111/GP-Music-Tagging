{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d149e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training baseline model M0 for all 3 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1766fb5",
   "metadata": {},
   "source": [
    "# 0  Common imports & helper functions  (first cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aee0a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# baseline_notebook.py  –  PMF‑IAT feature baseline (Jupyter version)\n",
    "# ---------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, balanced_accuracy_score, precision_score, recall_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9c264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auc(clf, x_te, x_tr, y_tr, y_te, labels, weird_probas=False):\n",
    "    global feat_set_name\n",
    "    \"\"\"Compute per‑label and mean ROC‑AUC (Jamendo / MagnaTagATune).\"\"\"\n",
    "    preds_te = clf.predict_proba(x_te)\n",
    "    preds_tr = clf.predict_proba(x_tr)\n",
    "    auc_tr, auc_te = [], []\n",
    "    for i, tag in enumerate(labels):\n",
    "        p_tr = preds_tr[:, i] if weird_probas else preds_tr[i][:, 1]\n",
    "        p_te = preds_te[:, i] if weird_probas else preds_te[i][:, 1]\n",
    "        auc_tr.append(roc_auc_score(y_tr[tag], p_tr))\n",
    "        auc_te.append(roc_auc_score(y_te[tag], p_te))\n",
    "    print(\"Mean AUC  (train):\", np.mean(auc_tr))\n",
    "    print(\"Mean AUC  (test) :\", np.mean(auc_te))\n",
    "\n",
    "    # build and return DataFrame\n",
    "    df = pd.DataFrame([{\n",
    "        'feat_set_name': feat_set_name,\n",
    "        'auc_tr': np.mean(auc_tr),\n",
    "        'auc_te': np.mean(auc_te)\n",
    "    }])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350667a6",
   "metadata": {},
   "source": [
    "# 1  Feature‑set definitions  (second cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e4e417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Essentia 23 ‑ low/mid‑level signal descriptors ------------------\n",
    "E23 = [\n",
    "    'Danceability', 'Loudness', 'Chords-Changes-Rate', 'Dynamic-Complexity',\n",
    "    'Zerocrossingrate', 'Chords-Number-Rate', 'Pitch-Salience',\n",
    "    'Spectral-Centroid', 'Spectral-Complexity', 'Spectral-Decrease',\n",
    "    'Spectral-Energyband-High', 'Spectral-Energyband-Low',\n",
    "    'Spectral-Energyband-Middle-High', 'Spectral-Energyband-Middle-Low',\n",
    "    'Spectral-Entropy', 'Spectral-Flux', 'Spectral-Rolloff',\n",
    "    'Spectral-Spread', 'Onset-Rate', 'Length', 'BPM', 'Beats-Loud',\n",
    "    'Vocal-Instrumental'\n",
    "]\n",
    "\n",
    "# --- Mid‑level perceptual 7 ------------------------------------------\n",
    "ML7 = [\n",
    "    'Melody', 'Articulation', 'Rhythm Complexity', 'Rhythm Stability',\n",
    "    'Dissonance', 'Atonality', 'Mode'\n",
    "]\n",
    "\n",
    "# --- Symbolic / harmony 32 -------------------------------------------\n",
    "SYM32 = [\n",
    "    'Dominants', 'Subdominants', 'sub-sub', 'sub-dom', 'dom-sub',\n",
    "    'dom-tonic', 'glob-sub', 'glob-dom', 'sub-sub-dom', 'sub-dom-sub',\n",
    "    'dom-sub-dom', 'sub-dom-tonic', 'dom-tonic-sub', 'dom-sub-sub',\n",
    "    'sub-sub-sub', 'glob-sub-glob', 'glob-dom-tonic', 'glob-sub-sub',\n",
    "    'dom-dom', 'glob-glob', 'dom-dom-sub', 'glob-glob-dom',\n",
    "    'glob-dom-glob', 'glob-glob-sub', 'dom-dom-tonic', 'glob-sub-dom',\n",
    "    'dom-tonic-dom', 'glob-dom-sub', 'sub-dom-dom', 'dom-dom-dom',\n",
    "    'glob-dom-dom', 'glob-glob-glob'\n",
    "]\n",
    "\n",
    "ALL62 = ML7 + SYM32 + E23      # full perceptual set\n",
    "\n",
    "all = ['Melody','Articulation','Rhythm Complexity','Rhythm Stability', 'Dissonance', 'Atonality', 'Mode', \n",
    "    'Dominants', 'Subdominants', 'sub-sub', 'sub-dom', 'dom-sub', 'dom-tonic', 'glob-sub',  'glob-dom', \n",
    "    'sub-sub-dom', 'sub-dom-sub', 'dom-sub-dom', 'sub-dom-tonic', 'dom-tonic-sub', \n",
    "    'dom-sub-sub', 'sub-sub-sub', 'glob-sub-glob','glob-dom-tonic', 'glob-sub-sub', 'dom-dom', 'glob-glob',  'dom-dom-sub', 'glob-glob-dom', 'glob-dom-glob', \n",
    "    'glob-glob-sub',  'dom-dom-tonic', 'glob-sub-dom',  'dom-tonic-dom',  'glob-dom-sub', 'sub-dom-dom',  'dom-dom-dom','glob-dom-dom', 'glob-glob-glob',  'Danceability','Loudness','Chords-Changes-Rate','Dynamic-Complexity','Zerocrossingrate','Chords-Number-Rate'\n",
    "    ,'Pitch-Salience','Spectral-Centroid','Spectral-Complexity','Spectral-Decrease','Spectral-Energyband-High',\n",
    "    'Spectral-Energyband-Low','Spectral-Energyband-Middle-High','Spectral-Energyband-Middle-Low','Spectral-Entropy','Spectral-Flux','Spectral-Rolloff','Spectral-Spread','Onset-Rate','Length','BPM',\n",
    "    'Beats-Loud', 'Vocal-Instrumental']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51440604",
   "metadata": {},
   "source": [
    "# 2  Global hyper‑parameters  (third cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e268e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Choose feature subset for baseline:\n",
    "#   feat_set = E23        # -> “signal‑processing only”  (M0 of E1)\n",
    "#   feat_set = ALL62      # -> full perceptual set       (M0 of E2)\n",
    "# ---------------------------------------------------------------------\n",
    "feat_set = E23        # <‑‑ change here for E1 vs E2\n",
    "if feat_set == ALL62:\n",
    "    feat_set_name = \"ALL62\"\n",
    "elif feat_set == E23:\n",
    "    feat_set_name = \"E23\"\n",
    "# xgb_params_binary = dict(\n",
    "#     max_depth=3, learning_rate=0.1, n_estimators=70,\n",
    "#     gamma=7.56, min_child_weight=6,\n",
    "#     objective='binary:logistic', eval_metric='auc'\n",
    "# )\n",
    "# xgb_params_multi = dict(\n",
    "#     max_depth=2, learning_rate=0.3, objective='multi:softmax',\n",
    "#     num_class=10, importance_type='weight'\n",
    "# )\n",
    "xgb_gpu_binary = dict(\n",
    "    tree_method='hist', device='cuda',      # use CUDA kernels  :contentReference[oaicite:2]{index=2}\n",
    "    n_estimators=70,\n",
    "    max_depth=3, learning_rate=0.1,\n",
    "    gamma=7.56, min_child_weight=6,\n",
    "    objective='binary:logistic', eval_metric='auc'\n",
    ")\n",
    "\n",
    "xgb_gpu_multi = dict(\n",
    "    tree_method='hist', device='cuda',\n",
    "    max_depth=2, learning_rate=0.3,\n",
    "    objective='multi:softmax', num_class=10,     # GTZAN   :contentReference[oaicite:4]{index=4}\n",
    "    importance_type='weight'\n",
    ")\n",
    "\n",
    "lgb_gpu_params = dict(\n",
    "    boosting_type='gbdt',\n",
    "    device='gpu',                # turn on GPU  :contentReference[oaicite:5]{index=5}\n",
    "    gpu_platform_id=-1,          # -1 -> first platform  :contentReference[oaicite:6]{index=6}\n",
    "    gpu_device_id=0,             # or pick a specific card\n",
    "    n_estimators=300,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    objective='binary',\n",
    "    metric='auc'\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 4\n",
    "DATA_ROOT = Path('D:/ICASSP1_GPMusic')   # adjust if CSVs live elsewhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6096ae",
   "metadata": {},
   "source": [
    "# 3  MTG‑Jamendo workflow  (fourth cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "317cb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC  (train): 0.8387044660573596\n",
      "Mean AUC  (test) : 0.7191511378775602\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- Jamendo (multi‑label) --------------------\n",
    "train_csv = DATA_ROOT / 'mtg-jamendo/Ref_Perceptual_features/train.csv'\n",
    "val_csv   = DATA_ROOT / 'mtg-jamendo/Ref_Perceptual_features/validation.csv'\n",
    "test_csv  = DATA_ROOT / 'mtg-jamendo/Ref_Perceptual_features/test.csv'\n",
    "\n",
    "# Load + merge splits\n",
    "df_train = pd.read_csv(train_csv).drop(columns=['Track'])\n",
    "df_val   = pd.read_csv(val_csv).drop(columns=['Track'])\n",
    "df_test  = pd.read_csv(test_csv).drop(columns=['Track'])\n",
    "\n",
    "x_tr = pd.concat([df_train[feat_set], df_val[feat_set]])\n",
    "y_tr = pd.concat([df_train.drop(columns=all),\n",
    "                  df_val.drop(columns=all)])\n",
    "x_te = df_test[feat_set]\n",
    "y_te = df_test.drop(columns=all)\n",
    "labels = y_tr.columns.tolist()\n",
    "\n",
    "# Optional scaling (recommended)\n",
    "scaler = StandardScaler().fit(x_tr)\n",
    "x_tr, x_te = scaler.transform(x_tr), scaler.transform(x_te)\n",
    "\n",
    "# # Train\n",
    "# base_est = xgb.XGBClassifier(**xgb_params_binary)\n",
    "# jamendo_clf = MultiOutputClassifier(base_est).fit(x_tr, y_tr)\n",
    "# evaluate_auc(jamendo_clf, x_te, x_tr, y_tr, y_te, labels)\n",
    "\n",
    "# --- GPU XGBoost\n",
    "jamendo_xgb = MultiOutputClassifier(xgb.XGBClassifier(**xgb_gpu_binary))\n",
    "jamendo_xgb.fit(x_tr, y_tr)\n",
    "df_jamendo_xgb = evaluate_auc(jamendo_xgb, x_te, x_tr, y_tr, y_te, labels)\n",
    "df_jamendo_xgb.to_csv(DATA_ROOT / f'mtg-jamendo/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.csv')\n",
    "df_jamendo_xgb.to_pickle(DATA_ROOT / f'mtg-jamendo/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.pkl')\n",
    "\n",
    "# # --- GPU LightGBM\n",
    "# lgb_gpu = lgb.LGBMClassifier(**lgb_gpu_params)\n",
    "# jamendo_lgb = MultiOutputClassifier(lgb_gpu)\n",
    "# jamendo_lgb.fit(x_tr, y_tr)\n",
    "# evaluate_auc(jamendo_lgb, x_te, x_tr, y_tr, y_te, labels, weird_probas=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Jamendo (multi‑label) --------------------\n",
    "# Your existing data loading code\n",
    "train_csv = DATA_ROOT / 'mtg-jamendo/Ref_Perceptual_features/train.csv'\n",
    "val_csv   = DATA_ROOT / 'mtg-jamendo/Ref_Perceptual_features/validation.csv'\n",
    "test_csv  = DATA_ROOT / 'mtg-jamendo/Ref_Perceptual_features/test.csv'\n",
    "\n",
    "# Load + merge splits\n",
    "df_train = pd.read_csv(train_csv).drop(columns=['Track'])\n",
    "df_val   = pd.read_csv(val_csv).drop(columns=['Track'])\n",
    "df_test  = pd.read_csv(test_csv).drop(columns=['Track'])\n",
    "\n",
    "x_tr = pd.concat([df_train[feat_set], df_val[feat_set]])\n",
    "y_tr = pd.concat([df_train.drop(columns=all),\n",
    "                    df_val.drop(columns=all)])\n",
    "x_te = df_test[feat_set]\n",
    "y_te = df_test.drop(columns=all)\n",
    "labels = y_tr.columns.tolist()\n",
    "\n",
    "# Optional scaling (recommended)\n",
    "scaler = StandardScaler().fit(x_tr)\n",
    "x_tr_scaled = scaler.transform(x_tr)\n",
    "x_te_scaled = scaler.transform(x_te)\n",
    "\n",
    "# Split training data for GP (use validation split for GP fitness evaluation)\n",
    "split_idx = len(df_train)\n",
    "x_train_gp = x_tr_scaled[:split_idx]\n",
    "y_train_gp = y_tr.iloc[:split_idx]\n",
    "x_val_gp = x_tr_scaled[split_idx:]\n",
    "y_val_gp = y_tr.iloc[split_idx:]\n",
    "x_test_gp = x_te_scaled\n",
    "y_test_gp = y_te.values\n",
    "\n",
    "# # Train\n",
    "# base_est = xgb.XGBClassifier(**xgb_params_binary)\n",
    "# jamendo_clf = MultiOutputClassifier(base_est).fit(x_tr, y_tr)\n",
    "# evaluate_auc(jamendo_clf, x_te, x_tr, y_tr, y_te, labels)\n",
    "\n",
    "# --- GPU XGBoost\n",
    "jamendo_xgb = MultiOutputClassifier(xgb.XGBClassifier(**xgb_gpu_binary))\n",
    "jamendo_xgb.fit(x_train_gp, y_train_gp)\n",
    "df_jamendo_xgb = evaluate_auc(jamendo_xgb, x_val_gp, x_train_gp, y_train_gp, y_val_gp, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab01f43",
   "metadata": {},
   "source": [
    "# 4  MagnaTagATune workflow  (fifth cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f1beed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC  (train): 0.8671650571982085\n",
      "Mean AUC  (test) : 0.8345847319720278\n"
     ]
    }
   ],
   "source": [
    "# -------------------- MagnaTagATune (multi‑label 50 tags) ------------\n",
    "mtt_csv = DATA_ROOT / 'magnatagatune/Ref_Perceptual_features/perceptual_features.csv'\n",
    "music_tags = [\n",
    "        \"guitar\", \"classical\", \"slow\", \"techno\", \"strings\", \"drums\", \"electronic\", \n",
    "        \"rock\", \"fast\", \"piano\", \"ambient\", \"beat\", \"violin\", \"vocal\", \"synth\", \n",
    "        \"female\", \"indian\", \"opera\", \"male\", \"singing\", \"vocals\", \"no vocals\", \n",
    "        \"harpsichord\", \"loud\", \"quiet\", \"flute\", \"woman\", \"male vocal\", \"no vocal\", \n",
    "        \"pop\", \"soft\", \"sitar\", \"solo\", \"man\", \"classic\", \"choir\", \"voice\", \n",
    "        \"new age\", \"dance\", \"male voice\", \"female vocal\", \"beats\", \"harp\", \"cello\", \n",
    "        \"no voice\", \"weird\", \"country\", \"metal\", \"female voice\", \"choral\"\n",
    "    ]\n",
    "\n",
    "df = pd.read_csv(mtt_csv).drop(columns=['Track'])\n",
    "df.rename(columns={'dom': 'Dominants', 'sub': 'Subdominants'}, inplace=True)\n",
    "\n",
    "feat_set_MTAT = [item for item in feat_set if item not in ['Length', 'Vocal-Instrumental']]\n",
    "\n",
    "x = df[feat_set_MTAT]\n",
    "y = df[music_tags]\n",
    "labels = music_tags\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "    x, y, train_size=0.8, random_state=RANDOM_STATE)\n",
    "\n",
    "scaler = StandardScaler().fit(x_tr)\n",
    "x_tr, x_te = scaler.transform(x_tr), scaler.transform(x_te)\n",
    "\n",
    "# base_est = xgb.XGBClassifier(**xgb_params_binary)\n",
    "# mtt_clf  = MultiOutputClassifier(base_est).fit(x_tr, y_tr)\n",
    "# evaluate_auc(mtt_clf, x_te, x_tr, y_tr, y_te, labels)\n",
    "\n",
    "# GPU XGBoost\n",
    "mtt_xgb = MultiOutputClassifier(xgb.XGBClassifier(**xgb_gpu_binary)).fit(x_tr,y_tr)\n",
    "df_mtt_xgb = evaluate_auc(mtt_xgb,x_te,x_tr,y_tr,y_te,labels)\n",
    "df_mtt_xgb.to_csv(DATA_ROOT / f'magnatagatune/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.csv')\n",
    "df_mtt_xgb.to_pickle(DATA_ROOT / f'magnatagatune/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.pkl')\n",
    "\n",
    "# # GPU LightGBM\n",
    "# mtt_lgb = MultiOutputClassifier(lgb.LGBMClassifier(**lgb_gpu_params)).fit(x_tr,y_tr)\n",
    "# evaluate_auc(mtt_lgb,x_te,x_tr,y_tr,y_te,labels,weird_probas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f8c89",
   "metadata": {},
   "source": [
    "# 5  GTZAN workflow  (sixth cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01382365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB train acc: 0.9987484355444305\n",
      "XGB test  acc: 0.74\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- GTZAN (single‑label 10 genres) ----------------\n",
    "gtzan_csv = DATA_ROOT / 'GTZAN/Ref_Perceptual_features/perceptual_features.csv'\n",
    "df = pd.read_csv(gtzan_csv).drop(columns=['Track'])\n",
    "df.rename(columns={'dom': 'Dominants', 'sub': 'Subdominants'}, inplace=True)\n",
    "\n",
    "feat_set_GTZAN = [item for item in feat_set if item not in ['Vocal-Instrumental']]\n",
    "all_GTZAN = [item for item in all if item not in ['Vocal-Instrumental']]\n",
    "\n",
    "x = df[feat_set_GTZAN]\n",
    "y_1hot = df.drop(columns=all_GTZAN)        # 10 one‑hot genre cols\n",
    "genre_labels = y_1hot.columns.tolist()\n",
    "\n",
    "# Convert one‑hot row -> integer genre index\n",
    "y_int = y_1hot.values.argmax(axis=1)\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "    x, y_int, train_size=0.8, random_state=RANDOM_STATE)\n",
    "\n",
    "scaler = StandardScaler().fit(x_tr)\n",
    "x_tr, x_te = scaler.transform(x_tr), scaler.transform(x_te)\n",
    "\n",
    "# gtzan_clf = xgb.XGBClassifier(**xgb_params_multi)\n",
    "# gtzan_clf.fit(x_tr, y_tr)\n",
    "\n",
    "# print(\"Accuracy (train):\", accuracy_score(y_tr, gtzan_clf.predict(x_tr)))\n",
    "# print(\"Accuracy (test) :\", accuracy_score(y_te, gtzan_clf.predict(x_te)))\n",
    "\n",
    "# GPU XGBoost\n",
    "gtzan_xgb = xgb.XGBClassifier(**xgb_gpu_multi).fit(x_tr,y_tr)\n",
    "print(\"XGB train acc:\", accuracy_score(y_tr, gtzan_xgb.predict(x_tr)))\n",
    "print(\"XGB test  acc:\", accuracy_score(y_te, gtzan_xgb.predict(x_te)))\n",
    "\n",
    "# build and return DataFrame\n",
    "df_gtzan_xgb = pd.DataFrame([{\n",
    "    'feat_set_name': feat_set_name,\n",
    "    'acc_tr': np.mean(accuracy_score(y_tr, gtzan_xgb.predict(x_tr))),\n",
    "    'acc_te': np.mean(accuracy_score(y_te, gtzan_xgb.predict(x_te)))\n",
    "}])\n",
    "df_gtzan_xgb.to_csv(DATA_ROOT / f'GTZAN/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.csv')\n",
    "df_gtzan_xgb.to_pickle(DATA_ROOT / f'GTZAN/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca0421ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB train acc: 0.9984350547730829\n",
      "XGB val  acc: 0.69375\n",
      "XGB test  acc: 0.705\n",
      "E23\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- GTZAN (single‑label 10 genres) ----------------\n",
    "gtzan_csv = DATA_ROOT / 'GTZAN/Ref_Perceptual_features/perceptual_features.csv'\n",
    "df = pd.read_csv(gtzan_csv).drop(columns=['Track'])\n",
    "df.rename(columns={'dom': 'Dominants', 'sub': 'Subdominants'}, inplace=True)\n",
    "\n",
    "feat_set_GTZAN = [item for item in feat_set if item not in ['Vocal-Instrumental']]\n",
    "all_GTZAN = [item for item in all if item not in ['Vocal-Instrumental']]\n",
    "\n",
    "x = df[feat_set_GTZAN]\n",
    "y_1hot = df.drop(columns=all_GTZAN)        # 10 one‑hot genre cols\n",
    "genre_labels = y_1hot.columns.tolist()\n",
    "\n",
    "# Convert one‑hot row -> integer genre index\n",
    "y_int = y_1hot.values.argmax(axis=1)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    x, y_int, train_size=0.8, random_state=RANDOM_STATE)\n",
    "\n",
    "# 2) From the 80% “temp”, split out validation (20% of temp → 16% overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.2,\n",
    "    stratify=y_temp,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Optional scaling (recommended)\n",
    "scaler = StandardScaler().fit(X_temp)\n",
    "x_tr_scaled = scaler.transform(X_train)\n",
    "x_val_scaled = scaler.transform(X_val)\n",
    "x_te_scaled = scaler.transform(X_test)\n",
    "\n",
    "x_train_gp = x_tr_scaled\n",
    "y_train_gp = y_train\n",
    "x_val_gp = x_val_scaled\n",
    "y_val_gp = y_val\n",
    "x_test_gp = x_te_scaled\n",
    "y_test_gp = y_test\n",
    "\n",
    "# gtzan_clf = xgb.XGBClassifier(**xgb_params_multi)\n",
    "# gtzan_clf.fit(x_tr, y_tr)\n",
    "\n",
    "# print(\"Accuracy (train):\", accuracy_score(y_tr, gtzan_clf.predict(x_tr)))\n",
    "# print(\"Accuracy (test) :\", accuracy_score(y_te, gtzan_clf.predict(x_te)))\n",
    "\n",
    "# GPU XGBoost\n",
    "gtzan_xgb = xgb.XGBClassifier(**xgb_gpu_multi).fit(x_train_gp,y_train_gp)\n",
    "print(\"XGB train acc:\", accuracy_score(y_train_gp, gtzan_xgb.predict(x_train_gp)))\n",
    "print(\"XGB val  acc:\", accuracy_score(y_val_gp, gtzan_xgb.predict(x_val_gp)))\n",
    "print(\"XGB test  acc:\", accuracy_score(y_test_gp, gtzan_xgb.predict(x_test_gp)))\n",
    "print(feat_set_name)\n",
    "\n",
    "# # build and return DataFrame\n",
    "# df_gtzan_xgb = pd.DataFrame([{\n",
    "#     'feat_set_name': feat_set_name,\n",
    "#     'acc_tr': np.mean(accuracy_score(y_tr, gtzan_xgb.predict(x_tr))),\n",
    "#     'acc_te': np.mean(accuracy_score(y_te, gtzan_xgb.predict(x_te)))\n",
    "# }])\n",
    "# df_gtzan_xgb.to_csv(DATA_ROOT / f'GTZAN/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.csv')\n",
    "# df_gtzan_xgb.to_pickle(DATA_ROOT / f'GTZAN/Ref_Perceptual_features/M0_results_xgb_{feat_set_name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201-py39-cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
